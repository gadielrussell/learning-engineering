#separator:Tab
#html:true
#tags column:3
#deck:DSA Master Deck
What is a heap and what property defines it?	A <b>heap</b> is a <b>complete binary tree</b> stored in an array that satisfies the <b>heap property</b>:<br><br><b>Min-heap:</b> Every parent ≤ its children. Smallest element at root.<br><b>Max-heap:</b> Every parent ≥ its children. Largest element at root.<br><br><b>Complete tree</b> means all levels are full except possibly the last, which is filled left to right. This is why it maps perfectly to an array with no gaps.<br><br><b>Key distinction:</b> A heap is NOT a BST. In a BST, left < parent < right. In a heap, both children can be in any order relative to each other — only the parent-child relationship matters.	heaps::fundamentals
How is a heap stored in an array? What are the index formulas?	A heap uses a flat array where tree positions map to indices:<br><pre><code>For node at index i (0-indexed):<br>  Parent:      (i - 1) // 2<br>  Left child:  2 * i + 1<br>  Right child: 2 * i + 2</code></pre><br>Example min-heap: <code>[1, 3, 5, 7, 9, 8]</code><br><pre><code>        1(0)<br>       / \<br>     3(1) 5(2)<br>    / \   /<br>  7(3) 9(4) 8(5)</code></pre><br>No pointers needed — the complete tree property guarantees no wasted indices. This is why heaps are space-efficient: pure array, zero overhead.	heaps::fundamentals
What are the time complexities for all heap operations?	<b>Min-Heap / Max-Heap Operations:</b><br><br>• <b>Insert (push):</b> O(log n) — add at end, bubble up<br>• <b>Extract min/max (pop):</b> O(log n) — swap root with last, sift down<br>• <b>Peek (get min/max):</b> O(1) — just read index 0<br>• <b>Heapify (build from array):</b> O(n) — NOT O(n log n)!<br>• <b>Search:</b> O(n) — heap gives no search ordering<br>• <b>Delete arbitrary:</b> O(n) to find + O(log n) to fix<br><br><b>Space:</b> O(n) for the array.<br><br>The key insight: heaps give O(1) access to the min OR max, but not both, and not arbitrary elements. If you need both, use two heaps.	heaps::fundamentals
Why is building a heap (heapify) O(n) and not O(n log n)?	Heapify calls sift-down starting from the last non-leaf node up to the root. Most nodes are near the bottom and have very short sift-down distances:<br><br>• ~n/2 nodes are leaves (0 work)<br>• ~n/4 nodes sift down 1 level<br>• ~n/8 nodes sift down 2 levels<br>• ... only 1 node (root) sifts down log n levels<br><br>Total work = n/4 × 1 + n/8 × 2 + n/16 × 3 + ... = <b>O(n)</b> (converging geometric series).<br><br>In contrast, inserting n elements one-by-one is O(n log n) because each insertion is O(log n) and elements are near the top when first pushed. <b>Heapify is bottom-up; repeated insert is top-down.</b>	heaps::fundamentals
How does Python's heapq module work?	Python's <code>heapq</code> implements a <b>min-heap</b> only. Key functions:<br><pre><code>import heapq<br><br>heap = [3, 1, 4, 1, 5]<br>heapq.heapify(heap)         # O(n) — in-place, [1, 1, 4, 3, 5]<br><br>heapq.heappush(heap, 2)     # O(log n) — add element<br>smallest = heapq.heappop(heap)  # O(log n) — remove & return min<br><br>smallest = heap[0]          # O(1) — peek without removing<br><br># Push then pop in one operation (more efficient)<br>heapq.heappushpop(heap, 6)  # push 6, pop smallest<br>heapq.heapreplace(heap, 6)  # pop smallest, push 6<br><br># Get n largest/smallest<br>heapq.nlargest(3, heap)     # top 3 largest<br>heapq.nsmallest(3, heap)    # top 3 smallest</code></pre><br><code>heapq</code> operates on a regular Python list — it's not a separate class.	heaps::python
How do you simulate a max-heap in Python?	Python only provides min-heap. Negate values to simulate max-heap:<br><pre><code>import heapq<br><br># Max-heap by negating<br>max_heap = []<br>heapq.heappush(max_heap, -5)   # push 5<br>heapq.heappush(max_heap, -10)  # push 10<br>heapq.heappush(max_heap, -3)   # push 3<br><br>largest = -heapq.heappop(max_heap)  # returns 10<br>peek = -max_heap[0]                  # peek: 5</code></pre><br><b>Remember:</b> Negate on push AND on pop/peek. This works because the smallest negative number corresponds to the largest original value. For tuples, negate only the comparison key: <code>(-priority, value)</code>.	heaps::python
How do you use heapq with custom comparison (tuples)?	Python heapq compares elements using their natural ordering. For custom priority, use <b>tuples</b> — they compare element by element:<br><pre><code>import heapq<br>heap = []<br><br># (priority, tiebreaker, value)<br>heapq.heappush(heap, (3, 0, "low"))<br>heapq.heappush(heap, (1, 1, "high"))<br>heapq.heappush(heap, (1, 2, "also high"))<br><br>priority, _, val = heapq.heappop(heap)  # (1, 1, "high")</code></pre><br><b>Why the tiebreaker?</b> If priorities are equal, Python compares the next element. If that element isn't comparable (e.g., a ListNode), you get an error. An integer tiebreaker (like insertion order) prevents this.<br><br>This pattern is essential for merge k sorted lists, Dijkstra's, and task scheduling.	heaps::python
What is the sift-up (bubble-up) operation?	<b>Sift-up</b> restores heap property after inserting at the bottom. Compare the new element with its parent; swap if it violates the heap property. Repeat until the root or the property holds:<br><pre><code># Min-heap sift-up<br>def sift_up(heap, i):<br>    while i > 0:<br>        parent = (i - 1) // 2<br>        if heap[i] < heap[parent]:<br>            heap[i], heap[parent] = heap[parent], heap[i]<br>            i = parent<br>        else:<br>            break</code></pre><br><b>Time: O(log n)</b> — at most travels from leaf to root (tree height). Used by <code>heappush</code>.	heaps::fundamentals
What is the sift-down (heapify-down) operation?	<b>Sift-down</b> restores heap property from a node downward. Compare the node with both children; swap with the smaller child (min-heap) or larger child (max-heap). Repeat until a leaf or the property holds:<br><pre><code># Min-heap sift-down<br>def sift_down(heap, size, i):<br>    while 2 * i + 1 < size:<br>        smallest = i<br>        left = 2 * i + 1<br>        right = 2 * i + 2<br>        if left < size and heap[left] < heap[smallest]:<br>            smallest = left<br>        if right < size and heap[right] < heap[smallest]:<br>            smallest = right<br>        if smallest == i: break<br>        heap[i], heap[smallest] = heap[smallest], heap[i]<br>        i = smallest</code></pre><br><b>Time: O(log n)</b>. Used by <code>heappop</code> (after swapping root with last element) and by <code>heapify</code> (building the heap bottom-up).	heaps::fundamentals
How does heap sort work?	Two phases: build a max-heap, then repeatedly extract the max:<br><pre><code>def heap_sort(arr):<br>    n = len(arr)<br>    # Phase 1: Build max-heap — O(n)<br>    for i in range(n // 2 - 1, -1, -1):<br>        sift_down(arr, n, i)  # max-heap sift-down<br>    # Phase 2: Extract max repeatedly — O(n log n)<br>    for i in range(n - 1, 0, -1):<br>        arr[0], arr[i] = arr[i], arr[0]  # move max to end<br>        sift_down(arr, i, 0)  # restore heap in reduced size</code></pre><br><b>Time: O(n log n) always</b> (best, average, worst).<br><b>Space: O(1)</b> — in-place sorting.<br><br>After each extraction, the sorted portion grows from the right. The extracted elements are guaranteed sorted because each extraction gives the current maximum.	heaps::algorithms
What is the difference between a heap and a priority queue?	<b>Priority queue</b> is an <b>abstract data type</b> (ADT) — it defines what operations are available: insert with priority, extract highest/lowest priority.<br><br><b>Heap</b> is a <b>data structure</b> — it's the most common way to IMPLEMENT a priority queue.<br><br>Other implementations exist (sorted array, unsorted array, balanced BST) but heaps give the best balance:<br><br>• Unsorted array: O(1) insert, O(n) extract<br>• Sorted array: O(n) insert, O(1) extract<br>• <b>Heap: O(log n) insert, O(log n) extract</b> ← sweet spot<br>• Balanced BST: O(log n) both, but more complex and overhead<br><br>In interviews, "priority queue" and "heap" are often used interchangeably.	heaps::fundamentals
How do you find the kth largest element using a min-heap?	Maintain a min-heap of size k. The root is always the kth largest:<br><pre><code>import heapq<br>def findKthLargest(nums, k):<br>    heap = nums[:k]<br>    heapq.heapify(heap)  # O(k)<br>    for num in nums[k:]:<br>        if num > heap[0]:  # larger than current kth largest<br>            heapq.heapreplace(heap, num)  # O(log k)<br>    return heap[0]  # kth largest</code></pre><br><b>Time: O(n log k), Space: O(k)</b>.<br><br><b>Why min-heap for kth LARGEST?</b> The min-heap of size k acts as a "filter" — it holds the k largest elements seen so far, with the smallest of those (the kth largest) at the root. Elements smaller than the root are discarded.	heaps::algorithms
How do you find the top K frequent elements?	Count frequencies, then use a min-heap of size k to keep the top k:<br><pre><code>import heapq<br>from collections import Counter<br><br>def topKFrequent(nums, k):<br>    counts = Counter(nums)  # O(n)<br>    return heapq.nlargest(k, counts.keys(), key=counts.get)</code></pre><br><b>Time: O(n + m log k)</b> where m = unique elements. <b>Space: O(m)</b>.<br><br>Alternative explicit approach:<br><pre><code>def topKFrequent(nums, k):<br>    counts = Counter(nums)<br>    heap = []<br>    for num, freq in counts.items():<br>        heapq.heappush(heap, (freq, num))<br>        if len(heap) > k:<br>            heapq.heappop(heap)  # remove least frequent<br>    return [num for freq, num in heap]</code></pre><br>The min-heap evicts the least frequent element whenever it exceeds size k.	heaps::algorithms
How do you merge K sorted lists using a heap?	Push the first element of each list into a min-heap, then repeatedly extract-min and push the next element from that list:<br><pre><code>import heapq<br>def mergeKLists(lists):<br>    heap = []<br>    for i, lst in enumerate(lists):<br>        if lst:<br>            heapq.heappush(heap, (lst.val, i, lst))<br>    dummy = ListNode(0)<br>    curr = dummy<br>    while heap:<br>        val, i, node = heapq.heappop(heap)<br>        curr.next = node<br>        curr = curr.next<br>        if node.next:<br>            heapq.heappush(heap, (node.next.val, i, node.next))<br>    return dummy.next</code></pre><br><b>Time: O(N log k)</b> where N = total nodes, k = number of lists. <b>Space: O(k)</b>.<br>The heap always has at most k elements. The index <code>i</code> is a tiebreaker because ListNode isn't comparable.	heaps::algorithms
How do you find the median from a data stream using two heaps?	Use a <b>max-heap</b> for the lower half and a <b>min-heap</b> for the upper half. Median is the top of one or average of both:<br><pre><code>import heapq<br>class MedianFinder:<br>    def __init__(self):<br>        self.lo = []  # max-heap (negated) — lower half<br>        self.hi = []  # min-heap — upper half<br><br>    def addNum(self, num):<br>        heapq.heappush(self.lo, -num)<br>        # Ensure lo's max ≤ hi's min<br>        heapq.heappush(self.hi, -heapq.heappop(self.lo))<br>        # Balance sizes: lo can have at most 1 more<br>        if len(self.hi) > len(self.lo):<br>            heapq.heappush(self.lo, -heapq.heappop(self.hi))<br><br>    def findMedian(self):<br>        if len(self.lo) > len(self.hi):<br>            return -self.lo[0]<br>        return (-self.lo[0] + self.hi[0]) / 2</code></pre><br><b>addNum: O(log n), findMedian: O(1)</b>. The max-heap stores the smaller half, min-heap stores the larger half. Their tops are the two middle elements.	heaps::algorithms
How do you sort a k-sorted (nearly sorted) array optimally?	Each element is at most k positions from its sorted position. Use a min-heap of size k+1:<br><pre><code>import heapq<br>def sortKSorted(arr, k):<br>    heap = arr[:k+1]<br>    heapq.heapify(heap)  # O(k)<br>    result = []<br>    for i in range(k+1, len(arr)):<br>        result.append(heapq.heappop(heap))   # O(log k)<br>        heapq.heappush(heap, arr[i])         # O(log k)<br>    while heap:<br>        result.append(heapq.heappop(heap))<br>    return result</code></pre><br><b>Time: O(n log k), Space: O(k)</b>.<br><br><b>Why k+1?</b> The correct element for position 0 must be among indices 0 to k. A heap of size k+1 guarantees the minimum is the correct next element. When k is small, this massively beats O(n log n) sorting.	heaps::algorithms
How do you solve "K Closest Points to Origin" with a heap?	Use a max-heap of size k. Keep only the k closest points:<br><pre><code>import heapq<br>def kClosest(points, k):<br>    heap = []<br>    for x, y in points:<br>        dist = -(x*x + y*y)  # negate for max-heap<br>        if len(heap) < k:<br>            heapq.heappush(heap, (dist, x, y))<br>        elif dist > heap[0][0]:  # closer than farthest in heap<br>            heapq.heapreplace(heap, (dist, x, y))<br>    return [[x, y] for _, x, y in heap]</code></pre><br><b>Time: O(n log k), Space: O(k)</b>.<br><br>No need for <code>sqrt</code> — comparing squared distances preserves ordering. The max-heap (negated) keeps the k smallest distances by evicting the largest whenever a closer point is found.	heaps::algorithms
How do you reorganize a string so no two adjacent characters are the same?	Use a max-heap of (frequency, char). Always place the most frequent character, then swap it with the next most frequent:<br><pre><code>import heapq<br>from collections import Counter<br>def reorganizeString(s):<br>    counts = Counter(s)<br>    heap = [(-freq, ch) for ch, freq in counts.items()]<br>    heapq.heapify(heap)<br>    result = []<br>    prev = (0, '')  # previous character (held back)<br>    while heap:<br>        freq, ch = heapq.heappop(heap)<br>        result.append(ch)<br>        if prev[0] < 0:  # previous char still has remaining count<br>            heapq.heappush(heap, prev)<br>        prev = (freq + 1, ch)  # +1 because freq is negative<br>    return ''.join(result) if len(result) == len(s) else ""</code></pre><br><b>Time: O(n log k)</b> where k = unique chars. The "hold back" trick prevents placing the same character consecutively. If the result is shorter than input, rearrangement is impossible.	heaps::algorithms
How do you find the kth smallest element in a sorted matrix?	Use a min-heap. Start with the first element of each row, then extract-min and push the next element from that row:<br><pre><code>import heapq<br>def kthSmallest(matrix, k):<br>    n = len(matrix)<br>    heap = [(matrix[i][0], i, 0) for i in range(min(n, k))]<br>    heapq.heapify(heap)<br>    for _ in range(k):<br>        val, row, col = heapq.heappop(heap)<br>        if col + 1 < n:<br>            heapq.heappush(heap, (matrix[row][col+1], row, col+1))<br>    return val</code></pre><br><b>Time: O(k log min(n,k)), Space: O(min(n,k))</b>. This is the "merge k sorted lists" pattern applied to matrix rows. Each row is a sorted list, and the heap merges them lazily.	heaps::algorithms
How do you implement a task scheduler with cooldown using a heap?	Count frequencies, use a max-heap + a cooldown queue to track when tasks become available:<br><pre><code>import heapq<br>from collections import Counter, deque<br>def leastInterval(tasks, n):<br>    counts = Counter(tasks)<br>    heap = [-freq for freq in counts.values()]<br>    heapq.heapify(heap)<br>    cooldown = deque()  # (available_time, neg_freq)<br>    time = 0<br>    while heap or cooldown:<br>        time += 1<br>        if heap:<br>            freq = heapq.heappop(heap) + 1  # +1 = decrement (neg)<br>            if freq < 0:<br>                cooldown.append((time + n, freq))<br>        if cooldown and cooldown[0][0] == time:<br>            heapq.heappush(heap, cooldown.popleft()[1])<br>    return time</code></pre><br><b>Time: O(n_tasks × log 26), Space: O(26) = O(1)</b>. The heap picks the most frequent available task (greedy). The cooldown queue holds tasks until their cooldown expires. Idle time occurs when the heap is empty but tasks are cooling down.	heaps::algorithms
What is the "lazy deletion" pattern for heaps?	Since heaps don't support efficient arbitrary deletion, <b>lazy deletion</b> marks elements as invalid and skips them during extraction:<br><pre><code># Pattern: track what's been "deleted" in a set<br>deleted = set()<br><br>def remove(heap, val):<br>    deleted.add(val)  # mark, don't actually remove<br><br>def get_min(heap):<br>    while heap and heap[0] in deleted:<br>        deleted.discard(heapq.heappop(heap))  # skip stale entries<br>    return heap[0] if heap else None</code></pre><br><b>When to use:</b> Dijkstra's algorithm (a node's distance gets updated, but old entries remain in heap), sliding window problems, any scenario where you need to "update" a heap entry. Amortized cost stays efficient since each element is pushed/popped at most once.	heaps::patterns
When should you use a min-heap vs max-heap?	<b>Min-heap (default in Python):</b><br>• Find the k <b>largest</b> elements (heap stores largest k, root = kth largest)<br>• Merge k sorted streams (always extract the smallest next element)<br>• Dijkstra's shortest path (extract minimum distance)<br>• Upper half in median-finding<br><br><b>Max-heap (negate values in Python):</b><br>• Find the k <b>smallest</b> elements (heap stores smallest k, root = kth smallest)<br>• Task scheduling by highest priority/frequency<br>• Lower half in median-finding<br><br><b>Counterintuitive pattern:</b> To find the k LARGEST elements, use a MIN-heap of size k. The min at the root is the "gatekeeper" — anything smaller gets rejected.	heaps::patterns
What are the key signals that a problem needs a heap?	Look for these patterns:<br><br><b>1. "Kth largest/smallest"</b> → Heap of size k<br><b>2. "Top K" or "K most frequent"</b> → Heap of size k<br><b>3. "Merge K sorted"</b> → Min-heap with one element per stream<br><b>4. "Median of stream"</b> → Two heaps (max + min)<br><b>5. "Continuously get min/max from dynamic data"</b> → Heap<br><b>6. "Schedule tasks by priority"</b> → Max-heap<br><b>7. "Nearest/closest K"</b> → Heap of size k<br><b>8. "Nearly sorted / K-sorted"</b> → Min-heap of size k+1<br><br><b>General rule:</b> If you repeatedly need the min or max from a changing collection, think heap. If you need both min AND max, think two heaps.	heaps::patterns
What is heapq.merge() and when do you use it?	<code>heapq.merge()</code> merges multiple sorted iterables into a single sorted output, lazily (one element at a time):<br><pre><code>import heapq<br>a = [1, 3, 5, 7]<br>b = [2, 4, 6, 8]<br>c = [0, 9, 10]<br>merged = list(heapq.merge(a, b, c))<br># [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</code></pre><br><b>Time: O(N log k)</b> where N = total elements, k = number of iterables.<br><b>Space: O(k)</b> — only holds one element per iterable in the heap.<br><br>Useful for merging sorted files, external sort, or any scenario with multiple sorted data sources. It's lazy — great for large data that doesn't fit in memory.	heaps::python
What is the difference between heapq.heappushpop() and heapq.heapreplace()?	Both combine push + pop into a single efficient operation, but the ORDER differs:<br><br><b>heappushpop(heap, val):</b> Push first, then pop. The returned value may be the one you just pushed (if it's the new minimum). Equivalent to push + pop but faster.<br><br><b>heapreplace(heap, val):</b> Pop first, then push. Always returns the old root, and the pushed value stays. Equivalent to pop + push but faster.<br><pre><code>heap = [1, 3, 5]<br>heapq.heappushpop(heap, 0)  # push 0, pop 0 → returns 0<br>heapq.heapreplace(heap, 0)  # pop 1, push 0 → returns 1</code></pre><br><b>Use heapreplace</b> in "k largest" patterns: pop the smallest, replace with the new candidate. <b>Use heappushpop</b> when you always want to add then trim.	heaps::python
How does a heap relate to a complete binary tree?	A heap IS a complete binary tree stored as an array. <b>Complete</b> means:<br>• Every level is full except possibly the last<br>• The last level is filled <b>left to right</b> with no gaps<br><br>This property is what makes the array representation work — there are no "holes" in the array. When you insert, you add to the next available position (end of array = next leaf position), maintaining completeness. When you delete the root, you swap with the last element (maintaining completeness) then sift down.<br><br><b>Contrast with BST:</b> A BST can be any shape (including a linked list). A heap is always a compact, wide tree with height exactly ⌊log n⌋.	heaps::fundamentals
How do you find the K closest elements to a target value in a sorted array?	Use a max-heap of size k storing (distance, value). Or exploit the sorted property with two pointers/binary search:<br><pre><code>import heapq<br>def findClosestElements(arr, k, x):<br>    # Heap approach<br>    heap = []  # max-heap by distance (negated)<br>    for num in arr:<br>        dist = abs(num - x)<br>        if len(heap) < k:<br>            heapq.heappush(heap, (-dist, num))<br>        elif -dist > heap[0][0]:  # closer than farthest in heap<br>            heapq.heapreplace(heap, (-dist, num))<br>    return sorted([num for _, num in heap])</code></pre><br><b>Time: O(n log k), Space: O(k)</b>. The max-heap keeps the k closest by evicting the farthest. Alternative: binary search for the closest starting window, then expand — O(log n + k).	heaps::algorithms
What is the "two heaps for sliding window" pattern?	When you need the median or balance of a sliding window, maintain two heaps and handle additions/removals:<br><br><b>Concept:</b><br>• Max-heap (lo) holds the smaller half<br>• Min-heap (hi) holds the larger half<br>• As the window slides: add new element, remove expired element, rebalance<br><br><b>Challenge:</b> Removing an arbitrary element from a heap is O(n). Use <b>lazy deletion</b>: track elements to remove in a hash map, skip them when they surface at the top.<br><br>This pattern appears in "Sliding Window Median" and similar problems. It's essentially the streaming median approach extended with window expiration and lazy cleanup.	heaps::patterns
How do you solve "Ugly Number II" (nth number whose only prime factors are 2, 3, 5)?	Use a min-heap to generate ugly numbers in order:<br><pre><code>import heapq<br>def nthUglyNumber(n):<br>    heap = [1]<br>    seen = {1}<br>    for _ in range(n):<br>        val = heapq.heappop(heap)<br>        for factor in [2, 3, 5]:<br>            nxt = val * factor<br>            if nxt not in seen:<br>                seen.add(nxt)<br>                heapq.heappush(heap, nxt)<br>    return val</code></pre><br><b>Time: O(n log n), Space: O(n)</b>. The heap always gives the next smallest ugly number. The set prevents duplicates (e.g., 6 = 2×3 = 3×2). Alternative O(n) solution uses three pointers (DP approach).	heaps::algorithms
What are common edge cases and pitfalls with heaps in Python?	<b>1. Python only has min-heap</b> — negate values for max-heap. Don't forget to negate back on extraction!<br><br><b>2. Non-comparable elements</b> — If two elements have equal priority, Python compares the next tuple element. If it's a ListNode or custom object, you get TypeError. Always include a tiebreaker: <code>(priority, counter, object)</code>.<br><br><b>3. heapify is in-place</b> — It modifies the input list. Don't assume it returns a new list.<br><br><b>4. Empty heap pops</b> — <code>heappop([])</code> raises IndexError. Always check <code>if heap</code> first.<br><br><b>5. Heap ≠ sorted</b> — <code>heap[1]</code> is NOT the second smallest. Only <code>heap[0]</code> is guaranteed to be the minimum. To get sorted order, you must pop n times.	heaps::python
What is the complexity comparison: heap vs sorting for "top K" problems?	<b>Finding top K from n elements:</b><br><br>• Full sort: <b>O(n log n)</b> time, O(1) extra space<br>• Heap of size k: <b>O(n log k)</b> time, O(k) space<br>• Quickselect: <b>O(n) average</b>, O(n) worst, O(1) space<br><br><b>When k << n:</b> Heap wins clearly. O(n log k) ≈ O(n) when k is small.<br><b>When k ≈ n:</b> Full sort is simpler and equally fast.<br><b>When k = 1:</b> Just scan for min/max in O(n). No heap needed.<br><br><b>Interview guidance:</b> Mention all three approaches, then choose heap for the best balance of guaranteed performance and simplicity. Mention quickselect as the optimal average-case solution if prompted.	heaps::patterns
