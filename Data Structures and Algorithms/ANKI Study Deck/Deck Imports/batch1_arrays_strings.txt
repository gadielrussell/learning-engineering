#separator:Tab
#html:true
#tags column:3
#deck:DSA Master Deck
What is an array and how is it stored in memory?	An array is a contiguous block of memory where elements are stored sequentially at fixed-size intervals. Because elements sit side-by-side in memory, any element can be accessed directly by computing its memory address: <code>base_address + (index × element_size)</code>. This is why index access is O(1). Python lists are dynamic arrays backed by a C array of pointers.	arrays::fundamentals
What is the time complexity of accessing an element by index in an array?	<b>O(1)</b> — constant time. The memory address is calculated directly: <code>base_address + (index × element_size)</code>. No traversal needed regardless of array size.	arrays::fundamentals
What is the time complexity of searching for a value in an unsorted array?	<b>O(n)</b> — linear time. You must potentially check every element since there's no ordering to exploit. This is called a linear scan or sequential search.	arrays::fundamentals
What is the time complexity of searching in a sorted array using binary search?	<b>O(log n)</b> — logarithmic time. Each comparison eliminates half the remaining elements. For an array of 1 million elements, binary search needs at most ~20 comparisons (log₂ 1,000,000 ≈ 20).	arrays::fundamentals
What is the time complexity of inserting at the END of a dynamic array?	<b>Amortized O(1)</b>. Most appends are O(1), but occasionally the array must resize (allocate new memory, copy all elements), which is O(n). Over many operations, the average cost per operation is O(1). Python's <code>list.append()</code> works this way.	arrays::fundamentals
What is the time complexity of inserting at the BEGINNING of an array?	<b>O(n)</b>. Every existing element must shift right by one position to make room at index 0. For a list of 1000 elements, that's 1000 shifts. Use <code>collections.deque</code> for O(1) left insertion in Python.	arrays::fundamentals
What is the time complexity of inserting in the MIDDLE of an array?	<b>O(n)</b>. All elements after the insertion point must shift right. On average, n/2 elements shift, which simplifies to O(n). <code>list.insert(i, val)</code> in Python.	arrays::fundamentals
What is the time complexity of deleting from the END of an array?	<b>O(1)</b>. No elements need to shift. Just remove the last element and decrement the length. <code>list.pop()</code> in Python.	arrays::fundamentals
What is the time complexity of deleting from the BEGINNING of an array?	<b>O(n)</b>. Every remaining element must shift left by one position. <code>list.pop(0)</code> in Python is O(n). Use <code>collections.deque.popleft()</code> for O(1).	arrays::fundamentals
What is the difference between a static array and a dynamic array?	<b>Static array</b>: Fixed size set at creation. Cannot grow or shrink. Used in C/C++ (<code>int arr[10]</code>).<br><br><b>Dynamic array</b>: Automatically resizes when full. Allocates a larger block (usually 2x), copies elements over. Python lists, Java ArrayList, C++ vector are all dynamic arrays. Trade-off: occasional O(n) resize cost for flexible sizing.	arrays::fundamentals
What does "amortized O(1)" mean for dynamic array append?	It means that while a single append <i>might</i> cost O(n) when resizing occurs, if you spread that cost across all appends, each one averages O(1). Example: If the array doubles when full, after n appends the total copy work is roughly n (1 + 2 + 4 + 8 + ... + n ≈ 2n), so per-operation cost is 2n/n = O(1).	arrays::fundamentals
What is a string in Python and why does immutability matter for algorithms?	A Python string is an <b>immutable sequence of characters</b>. You cannot modify it in place — every "modification" creates a new string. This means:<br>• <code>s += "a"</code> in a loop is O(n²) total because each concatenation creates a new string<br>• Use <code>"".join(list)</code> instead — build a list of parts, join once at the end for O(n) total	arrays::fundamentals
Why is string concatenation in a loop O(n²) and how do you fix it?	Each <code>s += char</code> creates a new string of length 1, then 2, then 3... so total work is 1+2+3+...+n = n(n+1)/2 = <b>O(n²)</b>.<br><br><b>Fix:</b> Collect parts in a list, then join:<br><pre><code>parts = []<br>for char in data:<br>    parts.append(char)<br>result = "".join(parts)  # O(n) total</code></pre>	arrays::fundamentals
What is Python's equivalent of StringBuilder?	Python doesn't have a StringBuilder class. The idiomatic approach is:<br><pre><code>parts = []<br>parts.append("hello")<br>parts.append(" ")<br>parts.append("world")<br>result = "".join(parts)</code></pre><br>This is O(n) total vs O(n²) for repeated string concatenation. The list acts as a mutable buffer.	arrays::fundamentals
When should you choose an array over a linked list?	<b>Choose arrays when:</b><br>• You need fast random access by index — O(1)<br>• Data size is relatively stable<br>• Cache performance matters (contiguous memory)<br>• You mostly append/remove from the end<br><br><b>Choose linked lists when:</b><br>• Frequent insert/delete at the beginning — O(1)<br>• Size varies dramatically<br>• No need for random access<br>• Implementing stacks, queues, or LRU caches	arrays::fundamentals
What is the two-pointer technique and when do you use it?	A technique that uses two index variables to traverse an array, often reducing O(n²) brute force to O(n). <b>Three main patterns:</b><br>1. <b>Opposite ends</b>: One pointer at start, one at end, moving inward (sorted array problems)<br>2. <b>Same direction</b>: Fast and slow pointers (partitioning, cycle detection)<br>3. <b>Two arrays</b>: One pointer per array (merge operations)	arrays::two_pointers
How do opposite-end two pointers work for "two sum in sorted array"?	Place <code>left</code> at index 0 and <code>right</code> at the last index. Compute the sum:<br>• If sum == target → found it<br>• If sum < target → move <code>left</code> right (need larger value)<br>• If sum > target → move <code>right</code> left (need smaller value)<br><br><pre><code>left, right = 0, len(arr) - 1<br>while left < right:<br>    total = arr[left] + arr[right]<br>    if total == target: return [left, right]<br>    elif total < target: left += 1<br>    else: right -= 1</code></pre><br><b>Time: O(n), Space: O(1)</b>	arrays::two_pointers
How do same-direction two pointers work (fast/slow)?	Both pointers start at the beginning and move in the same direction at different speeds or conditions. The slow pointer tracks the "write position" or boundary of the result.<br><br>Example — remove duplicates from sorted array:<br><pre><code>slow = 0<br>for fast in range(1, len(arr)):<br>    if arr[fast] != arr[slow]:<br>        slow += 1<br>        arr[slow] = arr[fast]<br>return slow + 1  # new length</code></pre><br><code>slow</code> marks the end of unique elements; <code>fast</code> scans ahead.	arrays::two_pointers
What is the Dutch National Flag algorithm (3-way partition)?	Partitions an array of 0s, 1s, and 2s in a single pass using three pointers:<br><pre><code>low, mid, high = 0, 0, len(arr) - 1<br>while mid <= high:<br>    if arr[mid] == 0:<br>        arr[low], arr[mid] = arr[mid], arr[low]<br>        low += 1; mid += 1<br>    elif arr[mid] == 1:<br>        mid += 1<br>    else:  # arr[mid] == 2<br>        arr[mid], arr[high] = arr[high], arr[mid]<br>        high -= 1</code></pre><br><b>Time: O(n), Space: O(1)</b>. The key insight: <code>low</code> tracks where 0s end, <code>high</code> tracks where 2s begin, <code>mid</code> scans.	arrays::two_pointers
How do you remove duplicates from a sorted array in-place?	Use slow/fast pointers. <code>slow</code> marks the last unique position; <code>fast</code> scans forward:<br><pre><code>def removeDuplicates(nums):<br>    if not nums: return 0<br>    slow = 0<br>    for fast in range(1, len(nums)):<br>        if nums[fast] != nums[slow]:<br>            slow += 1<br>            nums[slow] = nums[fast]<br>    return slow + 1</code></pre><br><b>Time: O(n), Space: O(1)</b>. Works because the array is sorted — duplicates are adjacent.	arrays::two_pointers
How do you reverse an array or string in-place with two pointers?	Swap elements at opposite ends and move inward:<br><pre><code>def reverse(arr):<br>    left, right = 0, len(arr) - 1<br>    while left < right:<br>        arr[left], arr[right] = arr[right], arr[left]<br>        left += 1<br>        right -= 1</code></pre><br><b>Time: O(n), Space: O(1)</b>. For strings (immutable in Python), convert to list first, reverse, then join.	arrays::two_pointers
How do you check if a string is a palindrome using two pointers?	Compare characters from both ends moving inward:<br><pre><code>def isPalindrome(s):<br>    left, right = 0, len(s) - 1<br>    while left < right:<br>        if s[left] != s[right]:<br>            return False<br>        left += 1<br>        right -= 1<br>    return True</code></pre><br><b>Time: O(n), Space: O(1)</b>. For "valid palindrome" problems, skip non-alphanumeric chars and compare case-insensitively.	arrays::two_pointers
What is the approach for "Container With Most Water"?	Use opposite-end two pointers. Area = min(height[l], height[r]) × (r - l). Move the pointer with the <b>shorter</b> height inward, because moving the taller one can only decrease or maintain the width without increasing the constraining height.<br><pre><code>left, right = 0, len(height) - 1<br>max_area = 0<br>while left < right:<br>    area = min(height[left], height[right]) * (right - left)<br>    max_area = max(max_area, area)<br>    if height[left] < height[right]:<br>        left += 1<br>    else:<br>        right -= 1</code></pre><br><b>Time: O(n), Space: O(1)</b>	arrays::two_pointers
How do you move all zeroes to the end of an array while maintaining order?	Use slow/fast two pointers. <code>slow</code> tracks the write position for non-zero elements:<br><pre><code>def moveZeroes(nums):<br>    slow = 0<br>    for fast in range(len(nums)):<br>        if nums[fast] != 0:<br>            nums[slow], nums[fast] = nums[fast], nums[slow]<br>            slow += 1</code></pre><br><b>Time: O(n), Space: O(1)</b>. Everything before <code>slow</code> is non-zero and in original order.	arrays::two_pointers
How does 3Sum reduce to a 2Sum problem?	Sort the array. Fix one element, then use two-pointer 2Sum on the remaining subarray:<br><pre><code>def threeSum(nums):<br>    nums.sort()<br>    result = []<br>    for i in range(len(nums) - 2):<br>        if i > 0 and nums[i] == nums[i-1]: continue  # skip dupes<br>        left, right = i + 1, len(nums) - 1<br>        while left < right:<br>            total = nums[i] + nums[left] + nums[right]<br>            if total == 0:<br>                result.append([nums[i], nums[left], nums[right]])<br>                while left < right and nums[left] == nums[left+1]: left += 1<br>                while left < right and nums[right] == nums[right-1]: right -= 1<br>                left += 1; right -= 1<br>            elif total < 0: left += 1<br>            else: right -= 1<br>    return result</code></pre><br><b>Time: O(n²), Space: O(1)</b> excluding output. Key: sort first, skip duplicates.	arrays::two_pointers
What is the sliding window technique?	A technique for processing contiguous subarrays/substrings by maintaining a "window" that expands and contracts. Instead of re-examining all elements, you add the new element entering the window and remove the one leaving.<br><br><b>Two types:</b><br>1. <b>Fixed-size</b>: Window always has k elements. Slide by adding right, removing left.<br>2. <b>Variable-size</b>: Window grows/shrinks based on a condition. Expand right, contract left when constraint violated.	arrays::sliding_window
What is the fixed-size sliding window pattern?	Maintain a window of exactly k elements. As you slide right, add the new element and remove the leftmost:<br><pre><code>def maxSumSubarray(arr, k):<br>    window_sum = sum(arr[:k])<br>    max_sum = window_sum<br>    for i in range(k, len(arr)):<br>        window_sum += arr[i] - arr[i - k]<br>        max_sum = max(max_sum, window_sum)<br>    return max_sum</code></pre><br><b>Time: O(n), Space: O(1)</b>. Key insight: Don't recompute the entire window sum — just adjust by the entering and leaving elements.	arrays::sliding_window
What is the variable-size sliding window pattern?	The window expands right until a condition breaks, then contracts from the left to restore it:<br><pre><code>left = 0<br>for right in range(len(arr)):<br>    # Expand: add arr[right] to window state<br>    while window_is_invalid():<br>        # Contract: remove arr[left] from window state<br>        left += 1<br>    # Update answer with current valid window</code></pre><br>Used for problems like "longest substring without repeating characters" or "minimum window substring."	arrays::sliding_window
How do you decide when to expand vs shrink a sliding window?	<b>Expand</b> (move right pointer): When the current window is valid and you want to find a longer/larger answer, OR when you haven't satisfied the condition yet.<br><br><b>Shrink</b> (move left pointer): When the current window violates the constraint and you need to restore validity.<br><br>Rule of thumb:<br>• Looking for <b>maximum</b> valid window? Expand eagerly, shrink only when invalid.<br>• Looking for <b>minimum</b> valid window? Expand until valid, then shrink to find the smallest valid window.	arrays::sliding_window
How do you find the maximum sum subarray of size k?	Fixed-size sliding window:<br><pre><code>def maxSumK(arr, k):<br>    window = sum(arr[:k])<br>    best = window<br>    for i in range(k, len(arr)):<br>        window += arr[i] - arr[i-k]  # slide: add new, drop old<br>        best = max(best, window)<br>    return best</code></pre><br><b>Time: O(n), Space: O(1)</b>. Brute force would be O(n×k) recomputing each window from scratch.	arrays::sliding_window
What is the approach for "Longest Substring Without Repeating Characters"?	Variable-size sliding window with a set (or hash map) to track characters in the current window:<br><pre><code>def lengthOfLongestSubstring(s):<br>    seen = set()<br>    left = 0<br>    max_len = 0<br>    for right in range(len(s)):<br>        while s[right] in seen:<br>            seen.remove(s[left])<br>            left += 1<br>        seen.add(s[right])<br>        max_len = max(max_len, right - left + 1)<br>    return max_len</code></pre><br><b>Time: O(n), Space: O(min(n, alphabet_size))</b>. Each character is added and removed at most once.	arrays::sliding_window
What is the approach for "Minimum Window Substring"?	Variable-size sliding window with frequency maps. Expand right to include all target chars, then shrink left to minimize:<br><pre><code>from collections import Counter<br>def minWindow(s, t):<br>    need = Counter(t)<br>    missing = len(t)<br>    left = start = 0<br>    min_len = float('inf')<br>    for right, char in enumerate(s):<br>        if need[char] > 0: missing -= 1<br>        need[char] -= 1<br>        while missing == 0:  # all chars found<br>            if right - left + 1 < min_len:<br>                min_len = right - left + 1<br>                start = left<br>            need[s[left]] += 1<br>            if need[s[left]] > 0: missing += 1<br>            left += 1<br>    return "" if min_len == float('inf') else s[start:start+min_len]</code></pre><br><b>Time: O(n), Space: O(alphabet)</b>	arrays::sliding_window
How do you use a frequency map with a sliding window?	Maintain a hash map of character/element counts within the window. Update on expand (add) and contract (remove):<br><pre><code>from collections import defaultdict<br>freq = defaultdict(int)<br>left = 0<br>for right in range(len(s)):<br>    freq[s[right]] += 1          # expand<br>    while some_condition_violated:<br>        freq[s[left]] -= 1        # contract<br>        if freq[s[left]] == 0:<br>            del freq[s[left]]     # clean up<br>        left += 1</code></pre><br>This tracks exactly what's in the current window at all times.	arrays::sliding_window
How do you track window state with a hash map?	The hash map stores element frequencies in the current window. Three operations:<br>1. <b>Add element</b>: <code>freq[element] += 1</code> (entering the window)<br>2. <b>Remove element</b>: <code>freq[element] -= 1</code> (leaving the window). Delete key if count hits 0.<br>3. <b>Check condition</b>: Compare freq map against a target (e.g., all chars present, at most k distinct keys).<br><br>This pattern enables O(1) membership and frequency queries within any window position.	arrays::sliding_window
What is the time complexity of sliding window algorithms?	<b>O(n)</b> in nearly all cases. Each element is processed at most twice: once when the right pointer includes it, once when the left pointer excludes it. Even though there's a nested while loop, the left pointer only moves forward across the entire algorithm, so total work is bounded by 2n.	arrays::sliding_window
How do you reverse a string using two pointers? (code snippet)	<pre><code>def reverseString(s: list) -> None:<br>    left, right = 0, len(s) - 1<br>    while left < right:<br>        s[left], s[right] = s[right], s[left]<br>        left += 1<br>        right -= 1</code></pre><br>Modifies in-place. <b>Time: O(n), Space: O(1)</b>. Note: works on a list of chars, not a string (strings are immutable in Python).	strings::manipulation
How do you check if two strings are anagrams?	Count character frequencies and compare. Two approaches:<br><br><b>Sorting approach</b>: Sort both strings and compare. <b>O(n log n)</b><br><br><b>Frequency count approach (preferred)</b>:<br><pre><code>from collections import Counter<br>def isAnagram(s, t):<br>    return Counter(s) == Counter(t)</code></pre><br><b>Time: O(n), Space: O(1)</b> since alphabet is fixed (26 letters). The Counter approach is preferred because it's O(n) vs O(n log n).	strings::manipulation
How do you group anagrams together?	Use sorted string as a hash key. All anagrams produce the same sorted string:<br><pre><code>from collections import defaultdict<br>def groupAnagrams(strs):<br>    groups = defaultdict(list)<br>    for s in strs:<br>        key = tuple(sorted(s))<br>        groups[key].append(s)<br>    return list(groups.values())</code></pre><br><b>Time: O(n × k log k)</b> where k is max string length.<br><br>Alternative: Use character count tuple as key for O(n × k).	strings::manipulation
How do you check for valid parentheses using a stack?	Push opening brackets onto a stack. For each closing bracket, check if it matches the top of the stack:<br><pre><code>def isValid(s):<br>    stack = []<br>    pairs = {')':'(', ']':'[', '}':'{'}<br>    for char in s:<br>        if char in pairs.values():<br>            stack.append(char)<br>        elif char in pairs:<br>            if not stack or stack[-1] != pairs[char]:<br>                return False<br>            stack.pop()<br>    return len(stack) == 0</code></pre><br><b>Time: O(n), Space: O(n)</b>. Key insight: most recent unmatched open bracket must match first.	strings::manipulation
What is the approach for "Longest Common Prefix"?	Compare characters column by column across all strings:<br><pre><code>def longestCommonPrefix(strs):<br>    if not strs: return ""<br>    for i in range(len(strs[0])):<br>        char = strs[0][i]<br>        for s in strs[1:]:<br>            if i >= len(s) or s[i] != char:<br>                return strs[0][:i]<br>    return strs[0]</code></pre><br><b>Time: O(S)</b> where S is the sum of all characters. Alternative: sort the array and compare only the first and last strings.	strings::manipulation
What are common edge cases for "string to integer" (atoi)?	1. <b>Leading whitespace</b>: strip it<br>2. <b>Sign</b>: optional +/- after whitespace<br>3. <b>Non-digit characters</b>: stop converting when you hit one<br>4. <b>Empty string or only whitespace</b>: return 0<br>5. <b>Overflow/underflow</b>: clamp to INT_MAX (2³¹-1) or INT_MIN (-2³¹)<br>6. <b>Leading zeroes</b>: "0042" → 42<br><br>Process: strip → check sign → read digits until non-digit → clamp to range.	strings::manipulation
What is the encode/decode strings pattern?	Used when you need to serialize a list of strings into a single string and back. Common approach: length-prefix encoding.<br><pre><code># Encode<br>def encode(strs):<br>    return "".join(f"{len(s)}#{s}" for s in strs)<br># "4#hello5#world"<br><br># Decode<br>def decode(s):<br>    result, i = [], 0<br>    while i < len(s):<br>        j = s.index('#', i)<br>        length = int(s[i:j])<br>        result.append(s[j+1:j+1+length])<br>        i = j + 1 + length<br>    return result</code></pre><br>Works with any characters because the length prefix tells you exactly how many chars to read.	strings::manipulation
What problem does KMP (Knuth-Morris-Pratt) solve and what is the key idea?	KMP solves <b>substring/pattern matching</b> in O(n + m) time instead of O(n × m) brute force. Key idea: When a mismatch occurs, don't restart from the beginning. Use a <b>failure/prefix table</b> that tells you the longest proper prefix of the pattern that is also a suffix, so you can skip ahead without missing matches.<br><br>Example: Searching "ABCABD" in text. If mismatch at 'D', the prefix table tells you "ABC" at the end matches "ABC" at the start, so shift pattern to continue from that point.	strings::manipulation
What is Rabin-Karp and when would you use it?	Rabin-Karp uses a <b>rolling hash</b> for substring search. Instead of comparing characters, compute a hash of the pattern and slide it across the text, updating the hash in O(1) as the window moves.<br><br><b>When to use:</b> Multiple pattern search (searching for many patterns at once), or when average-case O(n+m) is acceptable (worst case is still O(nm) due to hash collisions).<br><br>Key formula: <code>hash(s[i+1..i+m]) = (hash(s[i..i+m-1]) - s[i] × base^(m-1)) × base + s[i+m]</code>	strings::manipulation
How do you count character frequencies using a hash map?	<pre><code># Method 1: Manual counting<br>freq = {}<br>for char in s:<br>    freq[char] = freq.get(char, 0) + 1<br><br># Method 2: defaultdict<br>from collections import defaultdict<br>freq = defaultdict(int)<br>for char in s:<br>    freq[char] += 1<br><br># Method 3: Counter (most Pythonic)<br>from collections import Counter<br>freq = Counter(s)</code></pre><br>All are <b>O(n) time</b>. Counter is best for quick frequency analysis. Use get() or defaultdict when building incrementally.	strings::manipulation
What should you know about ASCII vs Unicode in string problems?	<b>ASCII</b>: 128 characters (0-127). Lowercase a-z are 97-122, uppercase A-Z are 65-90, digits 0-9 are 48-57.<br><br><b>Unicode</b>: Millions of characters from all languages.<br><br><b>For interviews:</b> Clarify the character set with the interviewer. If limited to lowercase English letters, you can use a fixed array of size 26 instead of a hash map:<br><pre><code>counts = [0] * 26<br>counts[ord(char) - ord('a')] += 1</code></pre><br>This is faster than a hash map due to direct indexing.	strings::manipulation
What is the time complexity of Python string slicing s[i:j]?	<b>O(j - i)</b> — linear in the size of the slice. Python creates a <b>new string object</b> and copies the characters. This means <code>s[1:]</code> inside a recursive call creates an O(n) copy each time, potentially turning O(n) recursion into O(n²) total. Prefer passing indices instead of slicing.	strings::manipulation
When would you use a Trie vs a hash map for string prefix problems?	<b>Use a Trie when:</b><br>• You need prefix matching ("find all words starting with 'app'")<br>• Autocomplete/typeahead functionality<br>• You need to check if any prefix exists<br>• Memory sharing matters (common prefixes stored once)<br><br><b>Use a hash map when:</b><br>• You only need exact match lookups<br>• You're grouping strings (anagrams)<br>• Simpler implementation is preferred<br>• No prefix operations needed	strings::manipulation
What is the iterative binary search template?	<pre><code>def binarySearch(arr, target):<br>    left, right = 0, len(arr) - 1<br>    while left <= right:<br>        mid = left + (right - left) // 2  # avoid overflow<br>        if arr[mid] == target:<br>            return mid<br>        elif arr[mid] < target:<br>            left = mid + 1<br>        else:<br>            right = mid - 1<br>    return -1  # not found</code></pre><br><b>Time: O(log n), Space: O(1)</b>. Use <code>left + (right - left) // 2</code> instead of <code>(left + right) // 2</code> to prevent integer overflow in other languages.	arrays::algorithms
When do you use left < right vs left <= right in binary search?	<b><code>left <= right</code></b>: Standard search for an exact target. The search space includes both endpoints. Loop ends when the pointers cross.<br><br><b><code>left < right</code></b>: Used when searching for a boundary/condition (e.g., first occurrence, insertion point). Loop ends when left == right, which IS the answer. Often paired with:<br>• <code>right = mid</code> (not mid-1) to keep mid as a candidate<br>• <code>left = mid + 1</code> to exclude mid<br><br>Choose based on: Are you looking for an exact value (<=) or a boundary condition (<)?	arrays::algorithms
What is Kadane's algorithm for maximum subarray sum?	Track the current subarray sum. If it drops below 0, reset — a negative sum only hurts the next element:<br><pre><code>def maxSubArray(nums):<br>    max_sum = curr_sum = nums[0]<br>    for num in nums[1:]:<br>        curr_sum = max(num, curr_sum + num)<br>        max_sum = max(max_sum, curr_sum)<br>    return max_sum</code></pre><br><b>Time: O(n), Space: O(1)</b>. The key insight: at each position, either extend the current subarray or start fresh. <code>max(num, curr_sum + num)</code> makes this decision.	arrays::algorithms
What is the prefix sum technique and what does it enable?	A prefix sum array where <code>prefix[i]</code> stores the sum of elements from index 0 to i. Build it in O(n), then answer range sum queries in O(1):<br><pre><code># Build prefix sum<br>prefix = [0] * (len(arr) + 1)<br>for i in range(len(arr)):<br>    prefix[i+1] = prefix[i] + arr[i]<br><br># Range sum query [i, j] inclusive<br>range_sum = prefix[j+1] - prefix[i]</code></pre><br><b>Build: O(n), Query: O(1)</b>. Works because sum(arr[i..j]) = sum(arr[0..j]) - sum(arr[0..i-1]).	arrays::algorithms
How does prefix sum enable O(1) range queries?	After building <code>prefix[i] = sum(arr[0..i-1])</code>, any range sum is just subtraction:<br><br><code>sum(arr[i..j]) = prefix[j+1] - prefix[i]</code><br><br>Example: arr = [2, 4, 1, 3, 5], prefix = [0, 2, 6, 7, 10, 15]<br>Sum of arr[1..3] = prefix[4] - prefix[1] = 10 - 2 = 8 ✓ (4+1+3=8)<br><br>Without prefix sum, each query scans O(n). With it, any number of queries is O(1) each after O(n) preprocessing.	arrays::algorithms
What is the approach for "Product of Array Except Self"?	Build two arrays: left products and right products. Then multiply them:<br><pre><code>def productExceptSelf(nums):<br>    n = len(nums)<br>    result = [1] * n<br>    # Left pass: result[i] = product of everything left of i<br>    left = 1<br>    for i in range(n):<br>        result[i] = left<br>        left *= nums[i]<br>    # Right pass: multiply by product of everything right of i<br>    right = 1<br>    for i in range(n-1, -1, -1):<br>        result[i] *= right<br>        right *= nums[i]<br>    return result</code></pre><br><b>Time: O(n), Space: O(1)</b> excluding output. The trick: use result array for left products, then multiply in-place with right products.	arrays::algorithms
What is the two-pointer approach for "Trapping Rain Water"?	Water at each position = min(max_left, max_right) - height. Use two pointers to track max heights from each side:<br><pre><code>def trap(height):<br>    left, right = 0, len(height) - 1<br>    left_max = right_max = 0<br>    water = 0<br>    while left < right:<br>        if height[left] < height[right]:<br>            if height[left] >= left_max:<br>                left_max = height[left]<br>            else:<br>                water += left_max - height[left]<br>            left += 1<br>        else:<br>            if height[right] >= right_max:<br>                right_max = height[right]<br>            else:<br>                water += right_max - height[right]<br>            right -= 1<br>    return water</code></pre><br><b>Time: O(n), Space: O(1)</b>. Process the shorter side because water is bounded by the shorter wall.	arrays::algorithms
What is the monotonic stack approach for "Next Greater Element"?	Use a stack that maintains decreasing order. When you find an element greater than the stack top, it's the "next greater" for that top element:<br><pre><code>def nextGreaterElement(nums):<br>    n = len(nums)<br>    result = [-1] * n<br>    stack = []  # stores indices<br>    for i in range(n):<br>        while stack and nums[i] > nums[stack[-1]]:<br>            idx = stack.pop()<br>            result[idx] = nums[i]<br>        stack.append(i)<br>    return result</code></pre><br><b>Time: O(n), Space: O(n)</b>. Each element is pushed and popped at most once. The stack always holds elements waiting for their next greater element.	arrays::algorithms
What is the approach for "Merge Intervals"?	Sort by start time, then merge overlapping intervals:<br><pre><code>def merge(intervals):<br>    intervals.sort(key=lambda x: x[0])<br>    merged = [intervals[0]]<br>    for start, end in intervals[1:]:<br>        if start <= merged[-1][1]:  # overlaps<br>            merged[-1][1] = max(merged[-1][1], end)<br>        else:<br>            merged.append([start, end])<br>    return merged</code></pre><br><b>Time: O(n log n)</b> for sorting. Key insight: after sorting, you only need to compare each interval with the last merged one. Overlap condition: current start ≤ previous end.	arrays::algorithms
How do you detect if any meetings overlap (Meeting Rooms)?	Sort meetings by start time. If any meeting starts before the previous one ends, there's an overlap:<br><pre><code>def canAttendMeetings(intervals):<br>    intervals.sort(key=lambda x: x[0])<br>    for i in range(1, len(intervals)):<br>        if intervals[i][0] < intervals[i-1][1]:<br>            return False<br>    return True</code></pre><br><b>Time: O(n log n), Space: O(1)</b>. For "minimum meeting rooms" (Meeting Rooms II), use a min-heap to track end times — that's a different problem.	arrays::algorithms
How do you rotate an array by k positions?	Three reversals approach (most elegant, O(1) space):<br><pre><code>def rotate(nums, k):<br>    k %= len(nums)  # handle k > n<br>    # Step 1: Reverse entire array<br>    nums.reverse()<br>    # Step 2: Reverse first k elements<br>    nums[:k] = reversed(nums[:k])<br>    # Step 3: Reverse remaining elements<br>    nums[k:] = reversed(nums[k:])</code></pre><br>Example: [1,2,3,4,5], k=2<br>Reverse all: [5,4,3,2,1]<br>Reverse first 2: [4,5,3,2,1]<br>Reverse rest: [4,5,1,2,3] ✓<br><b>Time: O(n), Space: O(1)</b>	arrays::algorithms
What is Boyer-Moore Voting Algorithm for finding the majority element?	Finds element appearing more than n/2 times in O(n) time, O(1) space:<br><pre><code>def majorityElement(nums):<br>    candidate = count = 0<br>    for num in nums:<br>        if count == 0:<br>            candidate = num<br>        count += 1 if num == candidate else -1<br>    return candidate</code></pre><br><b>Why it works:</b> The majority element appears more than all others combined. Pairs of different elements "cancel out," and the majority element always survives. Think of it as a battle — the majority army always has survivors.	arrays::algorithms
How does the Dutch National Flag algorithm group elements in minimum moves?	It partitions an array into three groups using three pointers (low, mid, high) in a single pass:<br>• Elements before <code>low</code>: group 0 (e.g., all 0s)<br>• Elements between <code>low</code> and <code>mid</code>: group 1<br>• Elements after <code>high</code>: group 2<br><br>This is optimal at O(n) because each element is examined at most once. The pattern generalizes to any 3-way partition problem (not just 0/1/2). Key: only increment <code>mid</code> when processing a 0 or 1, not a 2 (because the swapped element from <code>high</code> hasn't been examined yet).	arrays::algorithms
What is "binary search on answer" (search space reduction)?	Instead of searching for a target in an array, binary search over the <b>space of possible answers</b>. If you can write a function <code>isValid(x)</code> that determines if x is feasible, binary search finds the optimal x.<br><br>Example: "Minimum eating speed to finish bananas in h hours"<br>• Answer range: 1 to max(piles)<br>• <code>isValid(speed)</code>: can we finish all piles at this speed within h hours?<br>• Binary search for the minimum valid speed<br><br><b>Time: O(n × log(max_answer))</b>. Look for this pattern when the problem asks for "minimum/maximum value that satisfies a condition."	arrays::algorithms
What is cyclic sort and when do you use it?	Use when elements are in the range [1, n] or [0, n-1]. Place each element at its "correct" index by swapping:<br><pre><code>def cyclicSort(nums):  # for range [1, n]<br>    i = 0<br>    while i < len(nums):<br>        correct = nums[i] - 1<br>        if nums[i] != nums[correct]:<br>            nums[i], nums[correct] = nums[correct], nums[i]<br>        else:<br>            i += 1</code></pre><br><b>Time: O(n), Space: O(1)</b>. After sorting, any index where <code>nums[i] != i+1</code> reveals the missing/duplicate number. Perfect for "find the missing number" or "find the duplicate" problems.	arrays::algorithms
