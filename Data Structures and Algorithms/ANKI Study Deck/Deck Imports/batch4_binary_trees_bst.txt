#separator:Tab
#html:true
#tags column:3
#deck:DSA Master Deck
What is a binary tree?	A <b>binary tree</b> is a hierarchical data structure where each node has at most <b>two children</b> (left and right). The topmost node is the <b>root</b>. Nodes with no children are <b>leaves</b>.<br><pre><code>class TreeNode:<br>    def __init__(self, val=0, left=None, right=None):<br>        self.val = val<br>        self.left = left<br>        self.right = right</code></pre><br>Key property: there is exactly <b>one path</b> between any two nodes, and the structure has <b>no cycles</b>.	trees::binary_tree::fundamentals
What is the difference between depth and height in a tree?	<b>Depth</b> = distance from the <b>root</b> down to a specific node (root has depth 0).<br><b>Height</b> = longest path from a specific node down to a <b>leaf</b> (leaves have height 0).<br><br>The <b>height of the tree</b> = height of the root = depth of the deepest leaf.<br><br><pre><code>        1       ← depth 0, height 2<br>       / \<br>      2   3     ← depth 1, height 1 (node 2), height 0 (node 3)<br>     /<br>    4           ← depth 2, height 0</code></pre><br>Balanced tree height: <b>O(log n)</b>. Skewed tree height: <b>O(n)</b>.	trees::binary_tree::fundamentals
What are the types of binary trees (full, complete, perfect, balanced)?	<b>Full:</b> Every node has <b>0 or 2</b> children (no single-child nodes).<br><b>Complete:</b> All levels filled except possibly the last, which is filled <b>left to right</b>. (Heaps are complete trees.)<br><b>Perfect:</b> All internal nodes have 2 children AND all leaves are at the <b>same level</b>. A perfect tree with height h has 2^(h+1) - 1 nodes.<br><b>Balanced:</b> For every node, the heights of left and right subtrees differ by at most <b>1</b> (AVL definition). Guarantees O(log n) height.<br><br>Perfect ⊂ Complete ⊂ Binary Tree. Full and Complete are independent properties.	trees::binary_tree::fundamentals
What is a leaf node and how do you detect one in code?	A <b>leaf</b> is a node with <b>no children</b>:<br><pre><code>def is_leaf(node):<br>    return node and not node.left and not node.right</code></pre><br>This check matters in many problems: path sum (only count paths ending at leaves), collecting leaves, finding min/max depth. Common mistake: checking <code>not node</code> instead of checking if a node has no children — <code>None</code> is not a leaf; it's the absence of a node.	trees::binary_tree::fundamentals
How do you build a tree from code for testing?	<b>Nested construction</b> (most readable for small trees):<br><pre><code>root = TreeNode(1,<br>    TreeNode(2,<br>        TreeNode(4),<br>        TreeNode(5)),<br>    TreeNode(3,<br>        TreeNode(6),<br>        TreeNode(7)))</code></pre><br><b>Bottom-up</b> (clearer for understanding structure):<br><pre><code>n4, n5 = TreeNode(4), TreeNode(5)<br>n6, n7 = TreeNode(6), TreeNode(7)<br>n2 = TreeNode(2, n4, n5)<br>n3 = TreeNode(3, n6, n7)<br>root = TreeNode(1, n2, n3)</code></pre><br>Both produce the same tree. The nested version is great for quick test cases.	trees::binary_tree::fundamentals
What are the four tree traversal orders and when is each used?	<b>Preorder (Root → Left → Right):</b> Process node before children. Use for copying/serializing a tree, prefix expressions.<br><br><b>Inorder (Left → Root → Right):</b> Process node between children. Gives <b>sorted order</b> for BSTs. Use for BST validation, kth smallest.<br><br><b>Postorder (Left → Right → Root):</b> Process node after children. Use when you need children's info first (height, delete tree, postfix expressions).<br><br><b>Level-order (BFS):</b> Process level by level using a queue. Use for shortest path, level averages, rightmost node per level.<br><br>All are <b>O(n) time</b>. DFS traversals are <b>O(h) space</b>, BFS is <b>O(w) space</b>.	trees::traversals
What is the "when do I process" framework for choosing traversal order?	Ask: <b>"When do I do my work relative to visiting my children?"</b><br><br><b>Pre-order:</b> I need to process the current node <b>before</b> my children. (Passing info down — path building, serialization.)<br><br><b>In-order:</b> I process <b>between</b> left and right children. (Sorted traversal in BSTs — kth element, validation.)<br><br><b>Post-order:</b> I need my children's results <b>before</b> I can process myself. (Bubbling info up — height, diameter, subtree sums.)<br><br>Many tree problems combine these: pass info <b>down</b> via parameters (pre-order) and bubble results <b>up</b> via return values (post-order).	trees::traversals
How do you implement preorder traversal recursively and iteratively?	<b>Recursive:</b><br><pre><code>def preorder(root):<br>    if not root: return []<br>    return [root.val] + preorder(root.left) + preorder(root.right)</code></pre><br><b>Iterative (explicit stack):</b><br><pre><code>def preorder(root):<br>    if not root: return []<br>    result, stack = [], [root]<br>    while stack:<br>        node = stack.pop()<br>        result.append(node.val)<br>        if node.right: stack.append(node.right)  # right first!<br>        if node.left: stack.append(node.left)<br>    return result</code></pre><br><b>Time: O(n), Space: O(h)</b>. Push right <b>before</b> left so that left is popped first (LIFO). This produces Root → Left → Right order.	trees::traversals
How do you implement inorder traversal recursively and iteratively?	<b>Recursive:</b><br><pre><code>def inorder(root):<br>    if not root: return []<br>    return inorder(root.left) + [root.val] + inorder(root.right)</code></pre><br><b>Iterative (push all lefts, then process):</b><br><pre><code>def inorder(root):<br>    result, stack = [], []<br>    curr = root<br>    while curr or stack:<br>        while curr:          # go left as far as possible<br>            stack.append(curr)<br>            curr = curr.left<br>        curr = stack.pop()   # process node<br>        result.append(curr.val)<br>        curr = curr.right    # go right<br>    return result</code></pre><br><b>Time: O(n), Space: O(h)</b>. The iterative version uses two loops: inner loop pushes all left children, outer loop pops and goes right. This is the most common iterative traversal asked in interviews.	trees::traversals
How do you implement postorder traversal recursively and iteratively?	<b>Recursive:</b><br><pre><code>def postorder(root):<br>    if not root: return []<br>    return postorder(root.left) + postorder(root.right) + [root.val]</code></pre><br><b>Iterative (modified preorder, then reverse):</b><br><pre><code>def postorder(root):<br>    if not root: return []<br>    result, stack = [], [root]<br>    while stack:<br>        node = stack.pop()<br>        result.append(node.val)<br>        if node.left: stack.append(node.left)   # left first!<br>        if node.right: stack.append(node.right)<br>    return result[::-1]  # reverse gives postorder</code></pre><br><b>Time: O(n), Space: O(h)</b>. The trick: preorder is Root→L→R. If we do Root→R→L (push left before right) and reverse, we get L→R→Root = postorder. True iterative postorder without reversal is harder and rarely asked.	trees::traversals
How do you implement level-order (BFS) traversal?	Use a queue, processing one level at a time by capturing the queue's size:<br><pre><code>from collections import deque<br>def levelOrder(root):<br>    if not root: return []<br>    result, queue = [], deque([root])<br>    while queue:<br>        level = []<br>        for _ in range(len(queue)):  # process current level<br>            node = queue.popleft()<br>            level.append(node.val)<br>            if node.left: queue.append(node.left)<br>            if node.right: queue.append(node.right)<br>        result.append(level)<br>    return result</code></pre><br><b>Time: O(n), Space: O(w)</b> where w = max width. The <code>for _ in range(len(queue))</code> loop is the key technique — it processes exactly one level per outer iteration.	trees::traversals
What is the space complexity difference between DFS and BFS on trees?	<b>DFS (recursive or iterative):</b> O(h) where h = tree height.<br>• Balanced tree: O(log n)<br>• Skewed tree: O(n)<br><br><b>BFS (level-order):</b> O(w) where w = max width of the tree.<br>• Perfect tree: bottom level has n/2 nodes → O(n)<br>• Skewed tree: O(1) per level<br><br><b>Choose wisely:</b><br>• Very <b>wide</b> tree (many nodes per level)? DFS uses less space.<br>• Very <b>deep</b> tree (skewed/unbalanced)? BFS uses less space.<br>• Most interview trees are balanced, so both are O(n) worst case.	trees::traversals
How do you calculate the maximum depth (height) of a binary tree?	<b>Post-order pattern:</b> need children's heights first, then add 1:<br><pre><code>def maxDepth(root):<br>    if not root:<br>        return 0<br>    left = maxDepth(root.left)<br>    right = maxDepth(root.right)<br>    return 1 + max(left, right)</code></pre><br><b>Time: O(n), Space: O(h)</b>. This is the quintessential "bubble up" pattern — each node asks its children for their depth, takes the larger one, and adds 1 for itself. Base case: a null node has depth 0.	trees::patterns
How do you calculate the minimum depth of a binary tree?	Min depth is the shortest root-to-<b>leaf</b> path. BFS is ideal — the first leaf you encounter is the answer:<br><pre><code>from collections import deque<br>def minDepth(root):<br>    if not root: return 0<br>    queue = deque([(root, 1)])<br>    while queue:<br>        node, depth = queue.popleft()<br>        if not node.left and not node.right:<br>            return depth  # first leaf = min depth<br>        if node.left: queue.append((node.left, depth+1))<br>        if node.right: queue.append((node.right, depth+1))<br>    return 0</code></pre><br><b>Time: O(n), Space: O(w)</b>. BFS finds the shallowest leaf without exploring the entire tree. A DFS solution works but must visit every node to be sure.	trees::patterns
How do you find the diameter of a binary tree?	The diameter is the longest path between any two nodes (may not pass through root). At each node, the longest path through it = left height + right height:<br><pre><code>def diameterOfBinaryTree(root):<br>    max_diameter = [0]<br>    def height(node):<br>        if not node: return 0<br>        left = height(node.left)<br>        right = height(node.right)<br>        max_diameter[0] = max(max_diameter[0], left + right)<br>        return 1 + max(left, right)<br>    height(root)<br>    return max_diameter[0]</code></pre><br><b>Time: O(n), Space: O(h)</b>. This combines "pass down" and "bubble up": we compute height (return value) but also update a global max (side effect). <code>left + right</code> = the path length through the current node.	trees::patterns
How do you invert (mirror) a binary tree?	Swap left and right children at every node:<br><pre><code>def invertTree(root):<br>    if not root: return None<br>    root.left, root.right = root.right, root.left<br>    invertTree(root.left)<br>    invertTree(root.right)<br>    return root</code></pre><br><b>Time: O(n), Space: O(h)</b>. Pre-order or post-order both work — swap then recurse, or recurse then swap. The key is that every single node's children get swapped. Iterative with BFS also works (swap children as you dequeue each node).	trees::patterns
How do you check if two trees are identical?	Both trees must have the same structure AND same values at every node:<br><pre><code>def isSameTree(p, q):<br>    if not p and not q: return True<br>    if not p or not q: return False<br>    return (p.val == q.val and<br>            isSameTree(p.left, q.left) and<br>            isSameTree(p.right, q.right))</code></pre><br><b>Time: O(min(n,m)), Space: O(min(h1,h2))</b>. Three base cases: both null (equal), one null (not equal), then check values and recurse. Short-circuits on first mismatch.	trees::patterns
How do you check if a tree is symmetric (mirror of itself)?	A tree is symmetric if its left subtree is a mirror of its right subtree:<br><pre><code>def isSymmetric(root):<br>    def isMirror(left, right):<br>        if not left and not right: return True<br>        if not left or not right: return False<br>        return (left.val == right.val and<br>                isMirror(left.left, right.right) and<br>                isMirror(left.right, right.left))<br>    return isMirror(root.left, root.right) if root else True</code></pre><br><b>Time: O(n), Space: O(h)</b>. The trick: compare left.left with right.right (outer pair) and left.right with right.left (inner pair). It's like "isSameTree" but with mirrored recursion.	trees::patterns
How do you check if one tree is a subtree of another?	For each node in the main tree, check if the subtree rooted there is identical to the target:<br><pre><code>def isSubtree(root, subRoot):<br>    if not root: return False<br>    if isSameTree(root, subRoot): return True<br>    return isSubtree(root.left, subRoot) or isSubtree(root.right, subRoot)<br><br>def isSameTree(p, q):<br>    if not p and not q: return True<br>    if not p or not q: return False<br>    return (p.val == q.val and<br>            isSameTree(p.left, q.left) and<br>            isSameTree(p.right, q.right))</code></pre><br><b>Time: O(n × m)</b> where n = main tree, m = subtree. <b>Space: O(h)</b>. For each of n nodes, we potentially compare m nodes. Faster O(n) solutions exist using serialization + string matching.	trees::patterns
How do you find the path sum (root-to-leaf) in a binary tree?	Pass the remaining sum down, check at leaves:<br><pre><code>def hasPathSum(root, targetSum):<br>    if not root: return False<br>    targetSum -= root.val<br>    if not root.left and not root.right:  # leaf<br>        return targetSum == 0<br>    return (hasPathSum(root.left, targetSum) or<br>            hasPathSum(root.right, targetSum))</code></pre><br><b>Time: O(n), Space: O(h)</b>. This is the "pass down" (pre-order) pattern: subtract the current value and pass the remainder to children. Must check at <b>leaves only</b> — not at null nodes, which would give false positives for paths ending at internal nodes.	trees::patterns
How do you collect ALL root-to-leaf paths?	Use backtracking to build paths, record at leaves:<br><pre><code>def binaryTreePaths(root):<br>    result = []<br>    def dfs(node, path):<br>        if not node: return<br>        path.append(str(node.val))<br>        if not node.left and not node.right:<br>            result.append("->".join(path))<br>        else:<br>            dfs(node.left, path)<br>            dfs(node.right, path)<br>        path.pop()  # backtrack<br>    dfs(root, [])<br>    return result</code></pre><br><b>Time: O(n), Space: O(h)</b>. The <code>path.pop()</code> is backtracking — after exploring children, undo the choice so the path is clean for sibling branches. Alternative: pass immutable strings <code>path + str(node.val)</code> to avoid explicit backtracking (but uses more memory).	trees::patterns
How do you find the maximum path sum in a binary tree (any path)?	Any-to-any path (not just root-to-leaf). At each node, compute the best "one-arm" path (for parent's use) and the best "arch" path (through current node):<br><pre><code>def maxPathSum(root):<br>    max_sum = [float('-inf')]<br>    def dfs(node):<br>        if not node: return 0<br>        left = max(dfs(node.left), 0)   # ignore negative paths<br>        right = max(dfs(node.right), 0)<br>        # Arch through this node<br>        max_sum[0] = max(max_sum[0], left + node.val + right)<br>        # Return best single arm to parent<br>        return node.val + max(left, right)<br>    dfs(root)<br>    return max_sum[0]</code></pre><br><b>Time: O(n), Space: O(h)</b>. Key insight: <code>max(dfs(...), 0)</code> discards negative subtree paths. The return value is a single arm (can't fork), but the global update considers both arms.	trees::patterns
What is the "V-shape" visualization of recursion in tree problems?	Recursion on trees follows a V-shape:<br><br><b>Down slope (↘):</b> Recursive calls go deeper — you're "passing down" information via parameters (target sum, bounds, path so far).<br><br><b>Bottom of V:</b> You hit the base case (null node or leaf) — the smallest subproblem.<br><br><b>Up slope (↗):</b> Return values "bubble up" — children's results flow back to parents (heights, sums, booleans).<br><br><b>In code:</b><br><pre><code>def solve(node, param):     # ↘ pass down<br>    if not node: return base  # bottom<br>    left = solve(node.left, param)<br>    right = solve(node.right, param)<br>    return combine(left, right) # ↗ bubble up</code></pre><br>Many problems use BOTH directions simultaneously: pass bounds down (validate BST) while returning height up (diameter).	trees::patterns
How do you find the lowest common ancestor (LCA) in a binary tree?	LCA is the deepest node that has both p and q as descendants. Use post-order — check if p or q is found in left or right subtrees:<br><pre><code>def lowestCommonAncestor(root, p, q):<br>    if not root or root == p or root == q:<br>        return root<br>    left = lowestCommonAncestor(root.left, p, q)<br>    right = lowestCommonAncestor(root.right, p, q)<br>    if left and right: return root  # found one in each subtree<br>    return left or right  # both in one subtree</code></pre><br><b>Time: O(n), Space: O(h)</b>. If left and right both return non-null, the current node is the LCA. If only one side returns non-null, the answer is in that subtree.	trees::patterns
How do you find the LCA in a Binary Search Tree?	Exploit the BST property — no need to search both subtrees:<br><pre><code>def lowestCommonAncestor(root, p, q):<br>    while root:<br>        if p.val < root.val and q.val < root.val:<br>            root = root.left   # both in left subtree<br>        elif p.val > root.val and q.val > root.val:<br>            root = root.right  # both in right subtree<br>        else:<br>            return root  # split point = LCA<br>    return None</code></pre><br><b>Time: O(h), Space: O(1)</b> iterative. The split point where p and q diverge to different subtrees is the LCA. Much faster than the generic O(n) solution because BST ordering lets you eliminate half the tree each step.	trees::bst::operations
How do you collect tree nodes by level from leaves up (findLeaves)?	Compute each node's "level from bottom" = distance to its farthest leaf descendant. Use post-order with <code>max(left, right) + 1</code>:<br><pre><code>def findLeaves(root):<br>    result = []<br>    def dfs(node):<br>        if not node: return -1<br>        left = dfs(node.left)<br>        right = dfs(node.right)<br>        level = max(left, right) + 1<br>        while len(result) <= level:<br>            result.append([])<br>        result[level].append(node.val)<br>        return level<br>    dfs(root)<br>    return result</code></pre><br><b>Time: O(n), Space: O(n)</b>. Leaves get level 0 (max(-1,-1)+1=0). Each parent's level is one more than its deeper child. The <code>max()</code> ensures we measure from the <b>farthest</b> leaf descendant.	trees::patterns
How do you serialize and deserialize a binary tree?	Use preorder traversal with null markers for serialization:<br><pre><code>class Codec:<br>    def serialize(self, root):<br>        vals = []<br>        def dfs(node):<br>            if not node:<br>                vals.append("#")<br>                return<br>            vals.append(str(node.val))<br>            dfs(node.left)<br>            dfs(node.right)<br>        dfs(root)<br>        return ",".join(vals)<br><br>    def deserialize(self, data):<br>        vals = iter(data.split(","))<br>        def dfs():<br>            val = next(vals)<br>            if val == "#": return None<br>            node = TreeNode(int(val))<br>            node.left = dfs()<br>            node.right = dfs()<br>            return node<br>        return dfs()</code></pre><br><b>Time: O(n), Space: O(n)</b>. Preorder + null markers uniquely defines a tree. The iterator in deserialize consumes values in the same order they were produced.	trees::patterns
How do you build a tree from preorder and inorder traversals?	Preorder's first element is the root. Find it in inorder to split left/right subtrees:<br><pre><code>def buildTree(preorder, inorder):<br>    if not preorder: return None<br>    root = TreeNode(preorder[0])<br>    mid = inorder.index(preorder[0])<br>    root.left = buildTree(preorder[1:mid+1], inorder[:mid])<br>    root.right = buildTree(preorder[mid+1:], inorder[mid+1:])<br>    return root</code></pre><br><b>Time: O(n²)</b> due to <code>index()</code> and slicing. Optimize to <b>O(n)</b> with a hash map for inorder indices and pointer tracking instead of slicing.<br><br>Key insight: inorder splits tell you subtree sizes. preorder gives you the root of each subtree in order.	trees::patterns
What is a Binary Search Tree (BST) and what property defines it?	A BST is a binary tree where for every node:<br>• All values in the <b>left subtree</b> are <b>less than</b> the node's value<br>• All values in the <b>right subtree</b> are <b>greater than</b> the node's value<br>• This property holds <b>recursively</b> for every node<br><br><b>Critical:</b> The property applies to the <b>entire subtree</b>, not just immediate children. A node must be less than ALL ancestors it's a left descendant of, and greater than ALL ancestors it's a right descendant of.<br><br>BST enables O(log n) average search by eliminating half the tree at each step.	trees::bst::fundamentals
What are the time complexities for BST operations?	<b>Average (balanced) vs Worst (skewed):</b><br><br>• Search: <b>O(log n)</b> / O(n)<br>• Insert: <b>O(log n)</b> / O(n)<br>• Delete: <b>O(log n)</b> / O(n)<br>• Find min/max: <b>O(log n)</b> / O(n)<br>• Inorder successor: <b>O(log n)</b> / O(n)<br><br>Worst case occurs when the tree degenerates into a linked list (e.g., inserting sorted data). This is why self-balancing BSTs (AVL, Red-Black) exist — they guarantee O(log n) by maintaining balance.	trees::bst::fundamentals
Can a BST become unbalanced? Why?	<b>Yes!</b> The BST property only guarantees <b>ordering</b>, not <b>balance</b>. The shape depends entirely on <b>insertion order</b>.<br><br>Insert [1,2,3,4,5] → skewed (linked list, height = n):<br><pre><code>1<br> \<br>  2<br>   \<br>    3 ...</code></pre><br>Insert [3,1,4,2,5] → balanced (height = log n):<br><pre><code>    3<br>   / \<br>  1   4<br>   \   \<br>    2   5</code></pre><br>Same values, different structure. <b>Self-balancing BSTs</b> (AVL, Red-Black) add rebalancing rules (rotations) to prevent degeneracy.	trees::bst::fundamentals
How do you search for a value in a BST?	Use the BST property to choose left or right at each step:<br><pre><code>def searchBST(root, target):<br>    while root:<br>        if target == root.val: return root<br>        elif target < root.val: root = root.left<br>        else: root = root.right<br>    return None</code></pre><br><b>Time: O(h), Space: O(1)</b> iterative. Each comparison eliminates an entire subtree. This is NOT inorder traversal — it's directed binary search following one path. Inorder visits all nodes O(n); BST search visits one path O(log n) average.	trees::bst::operations
How do you insert a value into a BST?	Navigate to the correct null position and create the new node:<br><pre><code>def insertIntoBST(root, val):<br>    if not root: return TreeNode(val)<br>    if val < root.val:<br>        root.left = insertIntoBST(root.left, val)<br>    else:<br>        root.right = insertIntoBST(root.right, val)<br>    return root</code></pre><br><b>Time: O(h), Space: O(h)</b> recursive. The new node always becomes a leaf. The recursion returns the modified subtree root, which handles the case where the tree was initially empty.	trees::bst::operations
How do you delete a node from a BST?	Three cases based on the number of children:<br><pre><code>def deleteNode(root, key):<br>    if not root: return None<br>    if key < root.val:<br>        root.left = deleteNode(root.left, key)<br>    elif key > root.val:<br>        root.right = deleteNode(root.right, key)<br>    else:  # found the node<br>        if not root.left: return root.right   # case 1&2<br>        if not root.right: return root.left   # case 2<br>        # Case 3: two children - replace with inorder successor<br>        succ = root.right<br>        while succ.left:<br>            succ = succ.left<br>        root.val = succ.val<br>        root.right = deleteNode(root.right, succ.val)<br>    return root</code></pre><br><b>Time: O(h), Space: O(h)</b>. Case 1: no children (return None). Case 2: one child (return that child). Case 3: two children (replace value with inorder successor, then delete the successor).	trees::bst::operations
What is the inorder successor/predecessor in a BST?	<b>Inorder successor</b> = next larger value. Two cases:<br>1. Node has a right child → leftmost node in right subtree<br>2. No right child → nearest ancestor where node is in its left subtree<br><br><b>Inorder predecessor</b> = previous smaller value. Two cases:<br>1. Node has a left child → rightmost node in left subtree<br>2. No left child → nearest ancestor where node is in its right subtree<br><pre><code># Find successor in BST (search-based)<br>def successor(root, target):<br>    succ = None<br>    while root:<br>        if target < root.val:<br>            succ = root  # candidate<br>            root = root.left<br>        else:<br>            root = root.right<br>    return succ</code></pre><br><b>Time: O(h), Space: O(1)</b>.	trees::bst::operations
How do you find the min and max values in a BST?	<b>Min:</b> Follow left pointers to the leftmost node.<br><b>Max:</b> Follow right pointers to the rightmost node.<br><pre><code>def findMin(root):<br>    while root.left:<br>        root = root.left<br>    return root.val<br><br>def findMax(root):<br>    while root.right:<br>        root = root.right<br>    return root.val</code></pre><br><b>Time: O(h), Space: O(1)</b>. This follows directly from the BST property: the smallest value is always in the leftmost position, the largest in the rightmost.	trees::bst::operations
How do you validate if a binary tree is a valid BST?	<b>Approach 1: Bounds (pass constraints down):</b><br><pre><code>def isValidBST(root):<br>    def validate(node, lo, hi):<br>        if not node: return True<br>        if node.val <= lo or node.val >= hi:<br>            return False<br>        return validate(node.left, lo, node.val) and \<br>               validate(node.right, node.val, hi)<br>    return validate(root, float('-inf'), float('inf'))</code></pre><br><b>Approach 2: Inorder (check sorted order):</b><br><pre><code>def isValidBST(root):<br>    prev = [float('-inf')]<br>    def inorder(node):<br>        if not node: return True<br>        if not inorder(node.left): return False<br>        if node.val <= prev[0]: return False<br>        prev[0] = node.val<br>        return inorder(node.right)<br>    return inorder(root)</code></pre><br><b>Time: O(n), Space: O(h)</b>. The bounds approach tightens constraints as it descends. The inorder approach checks that values are strictly increasing.	trees::bst::operations
Why is checking only immediate children NOT enough for BST validation?	The BST property requires ALL values in a subtree to be less/greater, not just the direct child:<br><pre><code>        10<br>       /<br>      5<br>       \<br>        12  ← INVALID! 12 > 10 but is in left subtree</code></pre><br>Node 12 is a valid right child of 5 (12 > 5), but it violates the constraint inherited from node 10 (must be < 10 since it's in 10's left subtree).<br><br>The bounds approach catches this: when visiting 12, bounds are (5, 10). Since 12 ≥ 10, it fails. Checking only parent-child would miss this.	trees::bst::operations
How do you find the kth smallest element in a BST?	Inorder traversal visits BST nodes in sorted order. Count to k:<br><pre><code>def kthSmallest(root, k):<br>    stack = []<br>    curr = root<br>    while curr or stack:<br>        while curr:<br>            stack.append(curr)<br>            curr = curr.left<br>        curr = stack.pop()<br>        k -= 1<br>        if k == 0: return curr.val<br>        curr = curr.right<br>    return -1</code></pre><br><b>Time: O(h + k), Space: O(h)</b>. The iterative inorder is preferred here because you can stop early at the kth element. For the kth largest, do reverse inorder (right before left).	trees::bst::operations
How do you build a balanced BST from a sorted array?	Pick the middle element as root, recurse on left and right halves:<br><pre><code>def sortedArrayToBST(nums):<br>    if not nums: return None<br>    mid = len(nums) // 2<br>    root = TreeNode(nums[mid])<br>    root.left = sortedArrayToBST(nums[:mid])<br>    root.right = sortedArrayToBST(nums[mid+1:])<br>    return root</code></pre><br><b>Time: O(n), Space: O(n)</b> for slicing (O(log n) with index pointers). The middle element ensures equal-sized subtrees, guaranteeing O(log n) height. This is the reverse of inorder traversal — from sorted list back to BST.	trees::bst::operations
How do you convert a BST to a sorted doubly linked list (in-place)?	Use inorder traversal, linking each node to its predecessor:<br><pre><code>def treeToDoublyList(root):<br>    if not root: return None<br>    first = [None]<br>    last = [None]<br>    def inorder(node):<br>        if not node: return<br>        inorder(node.left)<br>        if last[0]:<br>            last[0].right = node<br>            node.left = last[0]<br>        else:<br>            first[0] = node  # leftmost = first<br>        last[0] = node<br>        inorder(node.right)<br>    inorder(root)<br>    # Make circular<br>    first[0].left = last[0]<br>    last[0].right = first[0]<br>    return first[0]</code></pre><br><b>Time: O(n), Space: O(h)</b>. Reuses <code>left</code> as <code>prev</code> pointer and <code>right</code> as <code>next</code> pointer. Inorder guarantees sorted order.	trees::bst::operations
How do you find all nodes within a range [low, high] in a BST?	Prune branches that can't contain values in range:<br><pre><code>def rangeSumBST(root, low, high):<br>    if not root: return 0<br>    if root.val < low:<br>        return rangeSumBST(root.right, low, high)<br>    if root.val > high:<br>        return rangeSumBST(root.left, low, high)<br>    return (root.val +<br>            rangeSumBST(root.left, low, high) +<br>            rangeSumBST(root.right, low, high))</code></pre><br><b>Time: O(h + k)</b> where k = nodes in range. <b>Space: O(h)</b>. BST ordering lets you skip entire subtrees: if current < low, nothing in the left subtree is in range (all values smaller). Same logic for right when current > high.	trees::bst::operations
How do you check if a binary tree is balanced?	A tree is balanced if for every node, left and right heights differ by at most 1. Compute height bottom-up and return -1 if unbalanced:<br><pre><code>def isBalanced(root):<br>    def height(node):<br>        if not node: return 0<br>        left = height(node.left)<br>        right = height(node.right)<br>        if left == -1 or right == -1: return -1  # propagate failure<br>        if abs(left - right) > 1: return -1     # unbalanced<br>        return 1 + max(left, right)<br>    return height(root) != -1</code></pre><br><b>Time: O(n), Space: O(h)</b>. Using -1 as a sentinel for "unbalanced" avoids redundant computation. Without this trick, checking balance at each node separately is O(n²).	trees::patterns
How do you find the right-side view of a binary tree?	BFS: take the last node at each level. Or DFS: visit right before left, record the first node seen at each depth:<br><pre><code># BFS approach<br>from collections import deque<br>def rightSideView(root):<br>    if not root: return []<br>    result, queue = [], deque([root])<br>    while queue:<br>        for i in range(len(queue)):<br>            node = queue.popleft()<br>            if node.left: queue.append(node.left)<br>            if node.right: queue.append(node.right)<br>        result.append(node.val)  # last node in level<br>    return result</code></pre><br><b>Time: O(n), Space: O(w)</b>. After the inner for loop, <code>node</code> holds the last (rightmost) node of that level. For left-side view, take the <b>first</b> node instead.	trees::patterns
How do you find the level averages of a binary tree?	BFS with level tracking — sum each level and divide:<br><pre><code>from collections import deque<br>def averageOfLevels(root):<br>    result, queue = [], deque([root])<br>    while queue:<br>        level_sum, level_count = 0, len(queue)<br>        for _ in range(level_count):<br>            node = queue.popleft()<br>            level_sum += node.val<br>            if node.left: queue.append(node.left)<br>            if node.right: queue.append(node.right)<br>        result.append(level_sum / level_count)<br>    return result</code></pre><br><b>Time: O(n), Space: O(w)</b>. The <code>range(level_count)</code> technique isolates each level. This same pattern adapts to finding level maximums, minimums, or sums.	trees::patterns
How do you flatten a binary tree to a linked list (in-place, preorder)?	Use a modified preorder: for each node, move the right subtree to the end of the left subtree, then move left to right:<br><pre><code>def flatten(root):<br>    curr = root<br>    while curr:<br>        if curr.left:<br>            # Find rightmost node of left subtree<br>            rightmost = curr.left<br>            while rightmost.right:<br>                rightmost = rightmost.right<br>            # Rewire: left subtree's rightmost → current's right<br>            rightmost.right = curr.right<br>            curr.right = curr.left<br>            curr.left = None<br>        curr = curr.right</code></pre><br><b>Time: O(n), Space: O(1)</b>. This is Morris-traversal style — no stack or recursion needed. Each node's left subtree gets threaded to the right side.	trees::patterns
How do you count the number of nodes in a complete binary tree in O(log²n)?	A complete tree's last level may be partially filled. Compare left and right heights to decide if subtrees are perfect:<br><pre><code>def countNodes(root):<br>    if not root: return 0<br>    left_h = right_h = 0<br>    l, r = root, root<br>    while l: left_h += 1; l = l.left<br>    while r: right_h += 1; r = r.right<br>    if left_h == right_h:  # perfect tree<br>        return 2**left_h - 1<br>    return 1 + countNodes(root.left) + countNodes(root.right)</code></pre><br><b>Time: O(log²n), Space: O(log n)</b>. If heights match, the tree is perfect (use formula). Otherwise, recurse — but at each level, one subtree is always perfect, so we only recurse O(log n) times, each costing O(log n) for height checks.	trees::patterns
How do you find the width of a binary tree (maximum number of nodes at any level)?	Use BFS and track the width at each level using positional indices:<br><pre><code>from collections import deque<br>def widthOfBinaryTree(root):<br>    if not root: return 0<br>    max_width = 0<br>    queue = deque([(root, 0)])  # (node, index)<br>    while queue:<br>        level_length = len(queue)<br>        _, first_idx = queue[0]<br>        for _ in range(level_length):<br>            node, idx = queue.popleft()<br>            if node.left: queue.append((node.left, 2*idx))<br>            if node.right: queue.append((node.right, 2*idx+1))<br>        max_width = max(max_width, idx - first_idx + 1)<br>    return max_width</code></pre><br><b>Time: O(n), Space: O(w)</b>. Index nodes like a heap: left = 2*i, right = 2*i+1. Width = last_index - first_index + 1 (counts null gaps between nodes).	trees::patterns
How do you find the zigzag (spiral) level-order traversal?	BFS with alternating direction each level:<br><pre><code>from collections import deque<br>def zigzagLevelOrder(root):<br>    if not root: return []<br>    result, queue = [], deque([root])<br>    left_to_right = True<br>    while queue:<br>        level = []<br>        for _ in range(len(queue)):<br>            node = queue.popleft()<br>            level.append(node.val)<br>            if node.left: queue.append(node.left)<br>            if node.right: queue.append(node.right)<br>        if not left_to_right:<br>            level.reverse()<br>        result.append(level)<br>        left_to_right = not left_to_right<br>    return result</code></pre><br><b>Time: O(n), Space: O(w)</b>. Normal BFS but reverse the level list on alternating levels. Could also use a deque and appendleft/append based on direction.	trees::patterns
What is Morris Traversal and why is it O(1) space?	Morris Traversal uses <b>threading</b> — temporarily modifying the tree to create shortcuts — achieving O(1) space inorder traversal:<br><pre><code>def morrisInorder(root):<br>    result = []<br>    curr = root<br>    while curr:<br>        if not curr.left:<br>            result.append(curr.val)  # process<br>            curr = curr.right<br>        else:<br>            # Find inorder predecessor<br>            pred = curr.left<br>            while pred.right and pred.right != curr:<br>                pred = pred.right<br>            if not pred.right:  # create thread<br>                pred.right = curr<br>                curr = curr.left<br>            else:  # thread exists, remove it<br>                pred.right = None<br>                result.append(curr.val)  # process<br>                curr = curr.right<br>    return result</code></pre><br><b>Time: O(n), Space: O(1)</b>. Threads let you return to ancestors without a stack. Each edge is created and removed once. Rarely asked to implement but good to know exists.	trees::traversals
What is the difference between BST search and inorder traversal?	These are fundamentally different operations:<br><br><b>BST Search (O(log n)):</b> Finding ONE specific value by choosing left or right at each step. You follow a single path and eliminate half the tree each step. Check current first, then pick ONE direction.<br><br><b>Inorder Traversal (O(n)):</b> Visiting ALL nodes in sorted order (Left → Root → Right). You must visit every node.<br><br><b>Common confusion:</b> "Inorder for BST validation" works because you need to visit ALL nodes and verify they're in sorted order — you're not searching, you're verifying a property of the entire tree.	trees::bst::fundamentals
What is the "pass down vs bubble up" pattern in tree problems?	<b>Pass down (pre-order):</b> Use function <b>parameters</b> to send info from parent to children.<br><pre><code># Pass remaining target sum down<br>def pathSum(node, remaining):<br>    remaining -= node.val  # modify before children</code></pre><br><b>Bubble up (post-order):</b> Use <b>return values</b> to send info from children to parent.<br><pre><code># Children's heights bubble up<br>def height(node):<br>    left = height(node.left)<br>    right = height(node.right)<br>    return 1 + max(left, right)  # combine and return</code></pre><br><b>Combine both:</b> Many problems do both simultaneously — pass bounds down (BST validate) while returning height up (diameter). The "V-shape" of recursion naturally supports this bidirectional flow.	trees::patterns
How do you approach tree problems systematically in interviews?	<b>Decision framework:</b><br><br>1. <b>What am I looking for?</b><br>• All paths → DFS + backtracking<br>• Shortest path / level info → BFS<br>• Kth element in BST → Inorder DFS<br>• Sorted order → Inorder<br><br>2. <b>What info do I need to track?</b><br>• Path from root → mutable list + backtrack<br>• Running sum → parameter (pass down)<br>• Children's results → return value (bubble up)<br><br>3. <b>When do I process?</b><br>• Need children's info first → Post-order<br>• Sorted BST order → In-order<br>• Process parent before children → Pre-order<br><br>4. <b>Check edge cases:</b> empty tree, single node, skewed tree, all same values	trees::patterns
What is the "count nodes in subtree" pattern using post-order?	Many problems need the size of each subtree. Compute bottom-up:<br><pre><code>def countNodes(root):<br>    if not root: return 0<br>    left = countNodes(root.left)<br>    right = countNodes(root.right)<br>    # Can use left, right counts here for any logic<br>    return 1 + left + right</code></pre><br>This pattern extends to: find largest BST subtree (validate + count), find most frequent subtree sum (sum + hash map), check equal tree partition (total sum / 2 matching). The key: each node knows its subtree's count/sum after children return.	trees::patterns
How do you do vertical order traversal of a binary tree?	Assign each node a column index. Root = 0, left = col-1, right = col+1. Group by column:<br><pre><code>from collections import defaultdict, deque<br>def verticalOrder(root):<br>    if not root: return []<br>    cols = defaultdict(list)<br>    queue = deque([(root, 0)])  # (node, column)<br>    while queue:<br>        node, col = queue.popleft()<br>        cols[col].append(node.val)<br>        if node.left: queue.append((node.left, col-1))<br>        if node.right: queue.append((node.right, col+1))<br>    return [cols[c] for c in sorted(cols)]</code></pre><br><b>Time: O(n log n)</b> for sorting columns, <b>Space: O(n)</b>. BFS ensures top-to-bottom order within each column. DFS would need to track depth for correct ordering.	trees::patterns
How do you find all nodes at distance K from a target node?	Convert tree to graph (add parent pointers), then BFS from target:<br><pre><code>from collections import deque<br>def distanceK(root, target, k):<br>    # Build parent map<br>    parent = {}<br>    def dfs(node, par):<br>        if not node: return<br>        parent[node] = par<br>        dfs(node.left, node)<br>        dfs(node.right, node)<br>    dfs(root, None)<br>    # BFS from target<br>    queue = deque([target])<br>    visited = {target}<br>    dist = 0<br>    while queue:<br>        if dist == k: return [n.val for n in queue]<br>        for _ in range(len(queue)):<br>            node = queue.popleft()<br>            for neighbor in [node.left, node.right, parent[node]]:<br>                if neighbor and neighbor not in visited:<br>                    visited.add(neighbor)<br>                    queue.append(neighbor)<br>        dist += 1<br>    return []</code></pre><br><b>Time: O(n), Space: O(n)</b>. The parent map turns the tree into an undirected graph, allowing BFS in all 3 directions (left, right, up).	trees::patterns
What are self-balancing BSTs (AVL and Red-Black) and when do they matter?	Both guarantee O(log n) operations by rebalancing after modifications:<br><br><b>AVL Tree:</b> Heights of subtrees differ by at most 1. Uses rotations (left, right, left-right, right-left). More strictly balanced → faster lookups, more rotations on insert/delete.<br><br><b>Red-Black Tree:</b> Nodes colored red/black with rules ensuring no path is more than 2× the shortest. Less strictly balanced → fewer rotations, slightly slower lookups.<br><br><b>In interviews:</b> You rarely implement these, but know they exist and why. Python's <code>sortedcontainers.SortedDict</code> and C#'s <code>SortedDictionary</code> use balanced BSTs internally. Mention them when discussing BST worst-case performance.	trees::bst::fundamentals
How do you convert a sorted linked list to a balanced BST?	Use slow/fast to find middle, then recurse on halves:<br><pre><code>def sortedListToBST(head):<br>    if not head: return None<br>    if not head.next: return TreeNode(head.val)<br>    # Find middle<br>    prev, slow, fast = None, head, head<br>    while fast and fast.next:<br>        prev = slow<br>        slow = slow.next<br>        fast = fast.next.next<br>    prev.next = None  # cut left half<br>    root = TreeNode(slow.val)<br>    root.left = sortedListToBST(head)<br>    root.right = sortedListToBST(slow.next)<br>    return root</code></pre><br><b>Time: O(n log n), Space: O(log n)</b>. Finding the middle is O(n) at each level, and there are O(log n) levels. For O(n) total, use inorder simulation with a global pointer advancing through the list.	trees::bst::operations
How do you find the sum of left leaves in a binary tree?	Track whether the current node is a left child, and only sum leaf values that are left children:<br><pre><code>def sumOfLeftLeaves(root):<br>    def dfs(node, is_left):<br>        if not node: return 0<br>        if not node.left and not node.right:  # leaf<br>            return node.val if is_left else 0<br>        return dfs(node.left, True) + dfs(node.right, False)<br>    return dfs(root, False)</code></pre><br><b>Time: O(n), Space: O(h)</b>. The boolean parameter passed down indicates parentage. Root is never a left leaf (is_left=False). Only leaf nodes that were reached via a left edge contribute to the sum.	trees::patterns
How do you determine if a binary tree is a "good node" (count nodes where path max ≤ node value)?	Pass the maximum value seen on the path from root:<br><pre><code>def goodNodes(root):<br>    def dfs(node, max_so_far):<br>        if not node: return 0<br>        good = 1 if node.val >= max_so_far else 0<br>        max_so_far = max(max_so_far, node.val)<br>        return good + dfs(node.left, max_so_far) + dfs(node.right, max_so_far)<br>    return dfs(root, root.val)</code></pre><br><b>Time: O(n), Space: O(h)</b>. Classic "pass down" pattern: the running maximum propagates from root to leaves via the parameter. A node is "good" if no ancestor on its path has a larger value.	trees::patterns
How do you find the closest value to a target in a BST?	Navigate the BST tracking the closest value seen:<br><pre><code>def closestValue(root, target):<br>    closest = root.val<br>    while root:<br>        if abs(root.val - target) < abs(closest - target):<br>            closest = root.val<br>        if target < root.val:<br>            root = root.left<br>        elif target > root.val:<br>            root = root.right<br>        else:<br>            return root.val  # exact match<br>    return closest</code></pre><br><b>Time: O(h), Space: O(1)</b>. The BST property guides you toward the target while you track the best candidate seen. You don't need to explore the other subtree because it's farther away.	trees::bst::operations
How do you trim a BST to only contain values in [low, high]?	Recursively prune: if a node is too small, its entire left subtree is too small; if too large, its entire right subtree is too large:<br><pre><code>def trimBST(root, low, high):<br>    if not root: return None<br>    if root.val < low:<br>        return trimBST(root.right, low, high)  # skip left subtree<br>    if root.val > high:<br>        return trimBST(root.left, low, high)   # skip right subtree<br>    root.left = trimBST(root.left, low, high)<br>    root.right = trimBST(root.right, low, high)<br>    return root</code></pre><br><b>Time: O(n), Space: O(h)</b>. BST ordering guarantees that if a node is out of range, all nodes in one direction are also out of range. Only recurse into subtrees that may contain valid values.	trees::bst::operations
What are the most common edge cases in binary tree problems?	<b>Always test with:</b><br>1. <b>Empty tree</b> (<code>root is None</code>)<br>2. <b>Single node</b> (root with no children)<br>3. <b>Skewed tree</b> (all nodes on one side — linked list shape)<br>4. <b>Perfect/balanced tree</b> (symmetric case)<br>5. <b>Negative values</b> (affects path sum, max sum problems)<br>6. <b>All same values</b> (BST: usually not valid; binary tree: all paths equal)<br>7. <b>Very large/deep tree</b> (consider stack overflow with recursion)<br><br>For BST specifically: sorted input creates worst-case skewed tree, and duplicate values need clarification (strict vs non-strict inequality).	trees::binary_tree::fundamentals
How do you use nonlocal or mutable containers to track state in tree recursion?	Nested functions can't reassign outer variables by default. Three solutions:<br><pre><code># 1. Mutable list (works everywhere)<br>def solve(root):<br>    result = [0]  # list is mutable<br>    def dfs(node):<br>        result[0] += 1  # modify contents<br>    dfs(root)<br>    return result[0]<br><br># 2. nonlocal keyword (Python 3)<br>def solve(root):<br>    result = 0<br>    def dfs(node):<br>        nonlocal result<br>        result += 1<br>    dfs(root)<br>    return result<br><br># 3. Class attribute<br>self.result = 0  # in a class-based solution</code></pre><br>This pattern appears in diameter, max path sum, count good nodes — any problem where you compute a <b>global best</b> while recursing through the tree.	trees::patterns
What is the time/space complexity summary for common tree operations?	<b>Traversal (all types):</b> O(n) time, O(h) space (DFS) or O(w) space (BFS)<br><br><b>BST Operations (balanced):</b><br>• Search / Insert / Delete: O(log n) time, O(h) space<br>• Find min/max: O(log n) time<br>• Kth smallest: O(h + k) time<br><br><b>Common Problems:</b><br>• Height / Depth / Diameter: O(n) time, O(h) space<br>• LCA (binary tree): O(n) time — must search both subtrees<br>• LCA (BST): O(h) time — use BST property<br>• Validate BST: O(n) time — must check every node<br>• Serialize/Deserialize: O(n) time, O(n) space<br>• Build from traversals: O(n) with hash map<br><br>Where h = height: O(log n) balanced, O(n) skewed.	trees::binary_tree::fundamentals
