#separator:Tab
#html:true
#tags column:3
#deck:DSA Master Deck
What is recursion and what are its essential components?	<b>Recursion</b> is a problem-solving technique where a function calls itself with modified inputs to solve progressively <b>smaller instances</b> of the same problem until reaching a base case.<br><br><b>Every recursive function needs:</b><br>1. <b>Base case(s):</b> When to stop (prevents infinite recursion / stack overflow)<br>2. <b>Recursive case:</b> How to break the problem into smaller subproblems<br>3. <b>Progress toward base case:</b> Each call must move closer to termination<br><pre><code>def factorial(n):<br>    if n <= 1: return 1        # base case<br>    return n * factorial(n - 1) # recursive case (n shrinks)</code></pre><br>The call stack stores each function's local state. When the base case returns, results "bubble up" through the chain of waiting calls.	recursion::fundamentals
What is the "recursive leap of faith" and why does it matter?	The <b>leap of faith</b> means trusting that your recursive call correctly solves the subproblem <b>without tracing through every step</b>. Focus on:<br><br>1. Does my base case return the correct answer for the smallest input?<br>2. If my recursive call correctly solves a smaller problem, does my code correctly combine it to solve the current problem?<br><br><b>Example — sum of list:</b><br><pre><code>def sum_list(arr):<br>    if not arr: return 0           # base: empty = 0 ✓<br>    return arr[0] + sum_list(arr[1:]) # leap: trust sum_list(arr[1:]) works</code></pre><br>If <code>sum_list([2,3])</code> correctly returns 5, then <code>1 + sum_list([2,3])</code> correctly returns 6. That's the only reasoning you need — don't manually trace every call.	recursion::fundamentals
What are the common parameter patterns in recursive functions?	Parameters represent the <b>current state</b> of the subproblem. Common patterns:<br><br><b>1. Index tracking:</b> Where are you in the data?<br><pre><code>def search(arr, target, index=0):  # index advances</code></pre><br><b>2. Accumulator:</b> Building up a result as you go<br><pre><code>def reverse(s, acc=""): return reverse(s[1:], s[0]+acc)</code></pre><br><b>3. Boundaries:</b> Narrowing a search space<br><pre><code>def binary_search(arr, target, left, right):</code></pre><br><b>4. Remaining work:</b> What's left to do<br><pre><code>def make_change(coins, remaining):</code></pre><br><b>Decision framework:</b><br>• What <b>changes</b> between calls? → Make it a parameter<br>• What <b>stays constant</b>? → Outer scope or closure<br>• What am I <b>building up</b>? → Accumulator parameter	recursion::fundamentals
What are the common return value patterns in recursion?	<b>1. Aggregate (combine children's results):</b><br><pre><code>def height(node):<br>    if not node: return 0<br>    return 1 + max(height(node.left), height(node.right))</code></pre><br><b>2. Boolean (found or not):</b><br><pre><code>def contains(node, target):<br>    if not node: return False<br>    if node.val == target: return True<br>    return contains(node.left, target) or contains(node.right, target)</code></pre><br><b>3. Void with side effects (collect into external list):</b><br><pre><code>def collect(node, result):<br>    if not node: return<br>    result.append(node.val)  # side effect<br>    collect(node.left, result)</code></pre><br><b>4. Pass-through (return what child returns):</b><br><pre><code>def find(node, target):<br>    if node.val == target: return node<br>    return find(node.next, target)</code></pre>	recursion::fundamentals
How does the call stack work during recursion?	Each recursive call adds a <b>stack frame</b> containing local variables, parameters, and the return address. Frames are removed (popped) when the function returns:<br><pre><code>factorial(3)<br>  → factorial(2)       # stack: [f(3), f(2)]<br>    → factorial(1)     # stack: [f(3), f(2), f(1)]<br>      ← returns 1      # stack: [f(3), f(2)]<br>    ← returns 2 * 1    # stack: [f(3)]<br>  ← returns 3 * 2      # stack: []</code></pre><br><b>Space: O(depth)</b> for the call stack. This is why deep recursion can cause <b>stack overflow</b>. Python's default recursion limit is ~1000.<br><br>The call stack is what makes "bubbling up" work — each frame waits for its child call to return, then uses that result.	recursion::fundamentals
What is the difference between recursion and backtracking?	<b>Recursion</b> = A <b>technique</b> (function calls itself). It's the vehicle/mechanism.<br><b>Backtracking</b> = A <b>strategy</b> (explore choices, undo bad ones). It's a specific use of recursion.<br><br><b>Recursion without backtracking:</b><br>• Factorial, Fibonacci, tree height<br>• No "undoing" — each call just computes and returns<br><br><b>Backtracking (recursion + undo):</b><br>• Permutations, N-Queens, Sudoku<br>• Make a choice → explore → <b>undo the choice</b> → try next option<br><br>The key backtracking operation is the <b>undo step</b> (e.g., <code>path.pop()</code>). Without it, you're just doing recursion. With it, you're systematically exploring a decision tree by trying all branches.	recursion::fundamentals
What is the universal backtracking template?	<pre><code>def backtrack(state, path, result):<br>    # BASE CASE: found a solution?<br>    if is_solution(state):<br>        result.append(path[:])  # copy!<br>        return<br><br>    # PRUNING: dead end?<br>    if not is_valid(state):<br>        return<br><br>    # EXPLORE: try each choice<br>    for choice in get_choices(state):<br>        path.append(choice)          # 1. CHOOSE<br>        backtrack(new_state, path, result)  # 2. EXPLORE<br>        path.pop()                   # 3. UNCHOOSE (backtrack)</code></pre><br><b>The three steps at each node:</b><br>1. <b>Choose:</b> Make a decision (add to path, mark visited)<br>2. <b>Explore:</b> Recurse into the next level<br>3. <b>Unchoose:</b> Undo the decision so siblings see clean state<br><br>The <code>path[:]</code> copy is critical — without it, all entries in result point to the same (eventually empty) list.	backtracking::template
Why must you copy the path when recording a backtracking solution?	In backtracking, <code>path</code> (or <code>current</code>) is a <b>mutable shared list</b> that gets modified throughout recursion. If you append it directly, all entries in result point to the same object:<br><pre><code># WRONG — all results point to same list<br>result.append(path)   # later pops will empty this<br><br># CORRECT — snapshot the current state<br>result.append(path[:])        # shallow copy<br>result.append(list(path))     # also works<br>result.append(path.copy())    # also works</code></pre><br><b>Why?</b> After appending, the algorithm continues popping and pushing. Without a copy, the reference in result tracks all future mutations. The <code>[:]</code> creates an independent snapshot frozen at that moment.<br><br><b>Exception:</b> If you use string concatenation (<code>current + "("</code>), no copy is needed because strings are immutable — each concatenation creates a new string.	backtracking::template
What is the "include/exclude" pattern (powerset/subsets)?	For each element, make a binary decision: <b>include it or skip it</b>. This creates a decision tree with 2 branches at each level:<br><pre><code>def subsets(nums):<br>    result = []<br>    def backtrack(index, current):<br>        if index == len(nums):<br>            result.append(current[:])<br>            return<br>        # Include nums[index]<br>        current.append(nums[index])<br>        backtrack(index + 1, current)<br>        # Exclude nums[index] (backtrack)<br>        current.pop()<br>        backtrack(index + 1, current)<br>    backtrack(0, [])<br>    return result</code></pre><br><b>Decision tree for [1,2,3]:</b><br><pre><code>         []<br>       /    \<br>     [1]     []       ← include 1?<br>    / \    / \<br> [1,2] [1] [2] []    ← include 2?<br>  ...  ...  ... ...   ← include 3?</code></pre><br><b>Time: O(n × 2ⁿ)</b> — 2ⁿ subsets, O(n) to copy each. <b>Space: O(n)</b> recursion depth.	backtracking::subsets
How do you generate subsets without duplicates?	Sort first, then skip consecutive duplicate elements at the same decision level:<br><pre><code>def subsetsWithDup(nums):<br>    nums.sort()  # critical!<br>    result = []<br>    def backtrack(index, current):<br>        result.append(current[:])<br>        for i in range(index, len(nums)):<br>            if i > index and nums[i] == nums[i-1]:<br>                continue  # skip duplicate at same level<br>            current.append(nums[i])<br>            backtrack(i + 1, current)<br>            current.pop()<br>    backtrack(0, [])<br>    return result</code></pre><br><b>Why sort?</b> Sorting groups duplicates together so the <code>nums[i] == nums[i-1]</code> check works. The condition <code>i > index</code> ensures we only skip duplicates at the <b>same branching level</b>, not the first occurrence.	backtracking::subsets
What is the "choose from remaining" pattern (permutations)?	At each position, choose <b>which unused element</b> to place. Use a <code>used</code> array or set to track availability:<br><pre><code>def permute(nums):<br>    result = []<br>    def backtrack(current, used):<br>        if len(current) == len(nums):<br>            result.append(current[:])<br>            return<br>        for i in range(len(nums)):<br>            if used[i]: continue<br>            used[i] = True<br>            current.append(nums[i])<br>            backtrack(current, used)<br>            current.pop()<br>            used[i] = False<br>    backtrack([], [False] * len(nums))<br>    return result</code></pre><br><b>Decision tree for [1,2,3]:</b><br><pre><code>           []<br>        /  |  \<br>      [1] [2] [3]      ← 3 choices<br>     / \  ...  ...<br>  [1,2] [1,3]          ← 2 remaining choices<br>   |      |<br>[1,2,3] [1,3,2]       ← 1 remaining choice</code></pre><br><b>Time: O(n × n!)</b> — n! permutations, O(n) to copy each.	backtracking::permutations
How do permutations differ from subsets in backtracking structure?	<b>Key differences:</b><br><br><b>Subsets:</b><br>• <b>Order doesn't matter:</b> {1,2} = {2,1}<br>• Use <b>index parameter</b> to avoid revisiting earlier elements<br>• Binary decision: include or exclude each element<br>• Output count: <b>2ⁿ</b><br><br><b>Permutations:</b><br>• <b>Order matters:</b> [1,2] ≠ [2,1]<br>• Use <b>used array</b> — any unused element can go in any remaining position<br>• Loop over ALL elements, skip used ones<br>• Output count: <b>n!</b><br><br><b>The structural difference:</b> Subsets use an index to move forward through elements (no looking back). Permutations loop from 0 every time but skip used elements (can pick any remaining element for any position).	backtracking::permutations
How do you generate permutations with duplicates?	Sort first, then skip duplicates at the same decision level (same as subsets dedup but with used array):<br><pre><code>def permuteUnique(nums):<br>    nums.sort()<br>    result = []<br>    used = [False] * len(nums)<br>    def backtrack(current):<br>        if len(current) == len(nums):<br>            result.append(current[:])<br>            return<br>        for i in range(len(nums)):<br>            if used[i]: continue<br>            # Skip duplicate: same value as previous AND previous not used<br>            if i > 0 and nums[i] == nums[i-1] and not used[i-1]:<br>                continue<br>            used[i] = True<br>            current.append(nums[i])<br>            backtrack(current)<br>            current.pop()<br>            used[i] = False<br>    backtrack([])<br>    return result</code></pre><br><b>Why <code>not used[i-1]</code>?</b> This ensures duplicates are used in order — the second copy of a value can only be used if the first copy is already in the current permutation. This prevents generating the same permutation twice.	backtracking::permutations
How do you generate combinations of size k (n choose k)?	Like subsets, but only record when you have exactly k elements. Use index to avoid duplicates:<br><pre><code>def combine(n, k):<br>    result = []<br>    def backtrack(start, current):<br>        if len(current) == k:<br>            result.append(current[:])<br>            return<br>        for i in range(start, n + 1):<br>            current.append(i)<br>            backtrack(i + 1, current)<br>            current.pop()<br>    backtrack(1, [])<br>    return result</code></pre><br><b>Pruning optimization:</b> If remaining elements aren't enough to reach k, stop early:<br><pre><code># Replace the for loop with:<br>for i in range(start, n - (k - len(current)) + 2):</code></pre><br><b>Time: O(k × C(n,k))</b>. The <code>start</code> parameter ensures combinations, not permutations: [1,2] is generated but [2,1] is not.	backtracking::combinations
How do you solve Combination Sum (reuse elements allowed)?	Start from each candidate, allowing reuse by NOT incrementing the index:<br><pre><code>def combinationSum(candidates, target):<br>    result = []<br>    def backtrack(start, current, remaining):<br>        if remaining == 0:<br>            result.append(current[:])<br>            return<br>        if remaining < 0:<br>            return  # pruning<br>        for i in range(start, len(candidates)):<br>            current.append(candidates[i])<br>            backtrack(i, current, remaining - candidates[i])  # i, not i+1!<br>            current.pop()<br>    backtrack(0, [], target)<br>    return result</code></pre><br><b>Key detail:</b> <code>backtrack(i, ...)</code> allows reusing the same element. For <b>no reuse</b>, use <code>backtrack(i + 1, ...)</code>.<br><br><b>Pruning:</b> Sort candidates first, then <code>if candidates[i] > remaining: break</code> — all subsequent candidates are also too large.	backtracking::combinations
How do you generate valid parentheses?	Track open and close counts. Can add '(' if under n, can add ')' if fewer than open count:<br><pre><code>def generateParenthesis(n):<br>    result = []<br>    def backtrack(current, open_count, close_count):<br>        if len(current) == 2 * n:<br>            result.append(current)<br>            return<br>        if open_count < n:<br>            backtrack(current + "(", open_count + 1, close_count)<br>        if close_count < open_count:<br>            backtrack(current + ")", open_count, close_count + 1)<br>    backtrack("", 0, 0)<br>    return result</code></pre><br><b>Time: O(4ⁿ/√n)</b> — the nth Catalan number.<br><br><b>Why no explicit undo?</b> String concatenation (<code>current + "("</code>) creates a <b>new string</b> each time — immutable, so no shared state to undo. This is an alternative to mutable list + pop. The two constraints (open < n, close < open) naturally produce only valid combinations.	backtracking::generation
How do you solve Letter Combinations of a Phone Number?	Map digits to letters, then backtrack through each digit's options:<br><pre><code>def letterCombinations(digits):<br>    if not digits: return []<br>    phone = {'2':'abc','3':'def','4':'ghi','5':'jkl',<br>             '6':'mno','7':'pqrs','8':'tuv','9':'wxyz'}<br>    result = []<br>    def backtrack(index, current):<br>        if index == len(digits):<br>            result.append(current)<br>            return<br>        for letter in phone[digits[index]]:<br>            backtrack(index + 1, current + letter)<br>    backtrack(0, "")<br>    return result</code></pre><br><b>Time: O(4ⁿ × n)</b> where n = number of digits (4 because some keys have 4 letters). Each digit contributes 3-4 branches. Uses immutable string concatenation so no explicit undo needed. This is also the foundation of <b>T9 predictive text</b>.	backtracking::generation
How do you solve Word Search (find word in grid)?	DFS + backtracking on the grid, marking cells as visited:<br><pre><code>def exist(board, word):<br>    rows, cols = len(board), len(board[0])<br>    def backtrack(r, c, i):<br>        if i == len(word): return True<br>        if (r<0 or r>=rows or c<0 or c>=cols or<br>            board[r][c] != word[i]): return False<br>        temp = board[r][c]<br>        board[r][c] = '#'  # mark visited<br>        for dr, dc in [(0,1),(0,-1),(1,0),(-1,0)]:<br>            if backtrack(r+dr, c+dc, i+1): return True<br>        board[r][c] = temp  # UNDO (backtrack)<br>        return False<br>    for r in range(rows):<br>        for c in range(cols):<br>            if backtrack(r, c, 0): return True<br>    return False</code></pre><br><b>Time: O(m×n × 4^L)</b> where L = word length. The backtracking is the <code>board[r][c] = temp</code> line — restoring the cell so other paths can use it. Short-circuits on first True.	backtracking::grid
How do you solve N-Queens?	Place queens row by row. Track which columns and diagonals are attacked:<br><pre><code>def solveNQueens(n):<br>    result = []<br>    cols = set()<br>    diag1 = set()  # row - col (↘ diagonal)<br>    diag2 = set()  # row + col (↙ diagonal)<br>    board = [['.' ]*n for _ in range(n)]<br>    def backtrack(row):<br>        if row == n:<br>            result.append([''.join(r) for r in board])<br>            return<br>        for col in range(n):<br>            if col in cols or row-col in diag1 or row+col in diag2:<br>                continue  # pruning<br>            board[row][col] = 'Q'<br>            cols.add(col); diag1.add(row-col); diag2.add(row+col)<br>            backtrack(row + 1)<br>            board[row][col] = '.'  # undo<br>            cols.remove(col); diag1.remove(row-col); diag2.remove(row+col)<br>    backtrack(0)<br>    return result</code></pre><br><b>Time: O(n!)</b>. Rows are implicit (one queen per row). The diagonal trick: cells on the same ↘ diagonal share <code>row-col</code>; cells on the same ↙ diagonal share <code>row+col</code>. Sets give O(1) conflict checking.	backtracking::constraint
How do you solve Sudoku?	Find empty cells, try digits 1-9, validate constraints, backtrack on failure:<br><pre><code>def solveSudoku(board):<br>    def is_valid(r, c, num):<br>        for i in range(9):<br>            if board[r][i] == num: return False<br>            if board[i][c] == num: return False<br>        box_r, box_c = 3*(r//3), 3*(c//3)<br>        for i in range(box_r, box_r+3):<br>            for j in range(box_c, box_c+3):<br>                if board[i][j] == num: return False<br>        return True<br>    def backtrack():<br>        for r in range(9):<br>            for c in range(9):<br>                if board[r][c] == '.':<br>                    for num in '123456789':<br>                        if is_valid(r, c, num):<br>                            board[r][c] = num<br>                            if backtrack(): return True<br>                            board[r][c] = '.'  # undo<br>                    return False  # no valid number works<br>        return True  # all cells filled<br>    backtrack()</code></pre><br><b>Time: O(9^m)</b> where m = empty cells (with pruning, much less). The <code>return False</code> after trying all digits triggers backtracking to the previous cell. Finding the <b>first valid solution</b>, not all.	backtracking::constraint
How do you solve Palindrome Partitioning?	Find all ways to partition a string into palindromes. At each position, try all possible palindromic prefixes:<br><pre><code>def partition(s):<br>    result = []<br>    def is_palindrome(sub):<br>        return sub == sub[::-1]<br>    def backtrack(start, current):<br>        if start == len(s):<br>            result.append(current[:])<br>            return<br>        for end in range(start + 1, len(s) + 1):<br>            substring = s[start:end]<br>            if is_palindrome(substring):<br>                current.append(substring)<br>                backtrack(end, current)<br>                current.pop()<br>    backtrack(0, [])<br>    return result</code></pre><br><b>Time: O(n × 2ⁿ)</b>. At each position, the "choice" is where to cut. Only extend paths where the current segment IS a palindrome (pruning). The start parameter advances past the consumed characters.	backtracking::partitioning
How do you solve "Restore IP Addresses" with backtracking?	Place 3 dots to create 4 valid segments (0-255, no leading zeros):<br><pre><code>def restoreIpAddresses(s):<br>    result = []<br>    def backtrack(start, segments):<br>        if len(segments) == 4:<br>            if start == len(s):<br>                result.append('.'.join(segments))<br>            return<br>        for length in range(1, 4):  # segments are 1-3 digits<br>            if start + length > len(s): break<br>            segment = s[start:start+length]<br>            if (segment[0] == '0' and length > 1): break  # no leading zeros<br>            if int(segment) > 255: break<br>            segments.append(segment)<br>            backtrack(start + length, segments)<br>            segments.pop()<br>    backtrack(0, [])<br>    return result</code></pre><br><b>Time: O(1)</b> — bounded at most 27 combinations (3 choices at each of 3 dot positions). The constraints (1-3 digit segments, 0-255 range, no leading zeros) heavily prune the search space.	backtracking::partitioning
What is the "V-shape" visualization of recursion?	Recursion on trees and recursive structures follows a V-shape:<br><br><b>Down slope (↘):</b> Recursive calls go deeper. You're "passing down" information via <b>parameters</b> (target sum, bounds, path).<br><br><b>Bottom of V:</b> Hit the base case — the smallest subproblem.<br><br><b>Up slope (↗):</b> Return values "bubble up." Children's results flow back to parents via <b>return values</b> (heights, counts, booleans).<br><pre><code>def solve(node, param):     # ↘ pass info DOWN<br>    if not node: return base  # bottom of V<br>    left = solve(node.left)   <br>    right = solve(node.right)<br>    return combine(left, right) # ↗ bubble UP</code></pre><br>Many problems use <b>BOTH directions simultaneously</b>: pass bounds down (validate BST) while returning height up (diameter). The V-shape is the natural flow of information in recursive algorithms.	recursion::fundamentals
What is memoization and how does it optimize recursion?	<b>Memoization</b> caches results of expensive recursive calls to avoid recomputation. Turns exponential into polynomial time for overlapping subproblems:<br><pre><code># Without memoization: O(2ⁿ)<br>def fib(n):<br>    if n <= 1: return n<br>    return fib(n-1) + fib(n-2)  # recomputes same values<br><br># With memoization: O(n)<br>def fib(n, memo={}):<br>    if n in memo: return memo[n]<br>    if n <= 1: return n<br>    memo[n] = fib(n-1, memo) + fib(n-2, memo)<br>    return memo[n]<br><br># Python shortcut:<br>from functools import lru_cache<br>@lru_cache(maxsize=None)<br>def fib(n):<br>    if n <= 1: return n<br>    return fib(n-1) + fib(n-2)</code></pre><br><b>When to memoize:</b> When you see <b>overlapping subproblems</b> (same function called with same arguments multiple times). Fibonacci has massive overlap; backtracking typically does NOT (each state is unique).	recursion::optimization
What is tail recursion and why does it matter?	<b>Tail recursion:</b> The recursive call is the <b>last operation</b> — nothing happens after it returns. Some languages optimize this to avoid stack growth:<br><pre><code># NOT tail recursive (multiplication happens AFTER return)<br>def factorial(n):<br>    if n <= 1: return 1<br>    return n * factorial(n - 1)  # must multiply after call returns<br><br># Tail recursive (accumulator carries the result)<br>def factorial(n, acc=1):<br>    if n <= 1: return acc<br>    return factorial(n - 1, n * acc)  # nothing after this call</code></pre><br><b>Python does NOT optimize tail recursion</b> (Guido van Rossum's design choice). So in Python, tail recursion doesn't save stack space. But it's a useful concept for understanding optimization and converting to iteration.	recursion::optimization
How do you convert recursion to iteration?	Use an <b>explicit stack</b> to simulate the call stack:<br><pre><code># Recursive DFS<br>def dfs(node):<br>    if not node: return<br>    process(node)<br>    dfs(node.left)<br>    dfs(node.right)<br><br># Iterative DFS<br>def dfs(root):<br>    stack = [root]<br>    while stack:<br>        node = stack.pop()<br>        if not node: continue<br>        process(node)<br>        stack.append(node.right)  # right first (LIFO)<br>        stack.append(node.left)</code></pre><br><b>When to convert:</b><br>• Deep recursion risks stack overflow<br>• Need to pause/resume traversal<br>• Interviewer asks specifically<br><br><b>Not all recursion converts easily:</b> Backtracking with complex state (N-Queens) is much harder to convert than simple tree DFS.	recursion::optimization
When should you use recursion vs iteration?	<b>Use recursion when:</b><br>• Problem has <b>recursive structure</b> (trees, nested data, divide & conquer)<br>• <b>Backtracking</b> is needed<br>• Code clarity matters more than performance<br>• Depth is manageable (< ~1000 in Python)<br><br><b>Use iteration when:</b><br>• Simple linear traversal (arrays, linked lists)<br>• Very deep recursion would cause stack overflow<br>• Performance is critical (no call overhead)<br>• State management is simple<br><br><b>Key insight:</b> Every recursive solution CAN be converted to iterative (using explicit stack), but recursion often gives cleaner, more intuitive code for naturally recursive problems. Trees and backtracking are almost always cleaner with recursion.	recursion::fundamentals
What is the "explore all paths" vs "find one path" distinction?	<b>Find ALL solutions:</b> Don't return early. Collect every valid result:<br><pre><code>def findAll(state, path, result):<br>    if is_solution(state):<br>        result.append(path[:])  # record but don't return<br>    for choice in choices:<br>        make(choice)<br>        findAll(new_state, path, result)<br>        undo(choice)</code></pre><br><b>Find ONE solution:</b> Return True immediately on first find:<br><pre><code>def findOne(state, path):<br>    if is_solution(state): return True<br>    for choice in choices:<br>        make(choice)<br>        if findOne(new_state, path): return True  # short-circuit!<br>        undo(choice)<br>    return False  # no choice worked</code></pre><br>The difference: "find all" always explores every branch. "Find one" short-circuits with <code>return True</code> as soon as any path succeeds. Sudoku is "find one." Permutations is "find all."	backtracking::template
What is pruning in backtracking and why is it important?	<b>Pruning</b> = cutting off branches of the decision tree that can't lead to valid solutions, avoiding wasted exploration:<br><pre><code># Without pruning: tries all 2ⁿ subsets then filters<br># With pruning: skips branches early<br>def combinationSum(candidates, target):<br>    candidates.sort()  # enables pruning<br>    result = []<br>    def backtrack(start, current, remaining):<br>        if remaining == 0:<br>            result.append(current[:]); return<br>        for i in range(start, len(candidates)):<br>            if candidates[i] > remaining:<br>                break  # PRUNE: all future candidates too large<br>            current.append(candidates[i])<br>            backtrack(i, current, remaining - candidates[i])<br>            current.pop()<br>    backtrack(0, [], target)<br>    return result</code></pre><br><b>Common pruning strategies:</b><br>• Sort + break when too large (combination sum)<br>• Skip duplicates (permutations/subsets with dups)<br>• Constraint checks (N-Queens column/diagonal sets)<br>• Remaining capacity checks (not enough elements left)	backtracking::template
How do you solve "Subsets that sum to target" (subset sum)?	Combine the include/exclude pattern with a running sum and pruning:<br><pre><code>def subsetSum(nums, target):<br>    nums.sort()  # enables pruning<br>    result = []<br>    def backtrack(index, current, remaining):<br>        if remaining == 0:<br>            result.append(current[:])<br>            return<br>        if remaining < 0: return  # pruning<br>        for i in range(index, len(nums)):<br>            if nums[i] > remaining: break  # pruning (sorted)<br>            if i > index and nums[i] == nums[i-1]: continue  # skip dups<br>            current.append(nums[i])<br>            backtrack(i + 1, current, remaining - nums[i])<br>            current.pop()<br>    backtrack(0, [], target)<br>    return result</code></pre><br><b>Time: O(2ⁿ)</b> worst case. Three pruning techniques combined: negative remaining, too-large elements (requires sort), and duplicate skipping. This pattern covers Combination Sum II.	backtracking::combinations
How do you solve "Generate All Binary Strings of Length n"?	At each position, choose 0 or 1. Pure binary branching:<br><pre><code>def generateBinaryStrings(n):<br>    result = []<br>    def backtrack(current):<br>        if len(current) == n:<br>            result.append(current)<br>            return<br>        backtrack(current + "0")<br>        backtrack(current + "1")<br>    backtrack("")<br>    return result</code></pre><br><b>Time: O(n × 2ⁿ), Space: O(n)</b>.<br><br>This is the simplest backtracking pattern — no constraints, no pruning, just pure exploration. It's useful as a starting point: every more complex backtracking problem is this template plus constraints. Add validity checks → parentheses. Add a used set → permutations.	backtracking::generation
How do you solve "Partition to K Equal Sum Subsets"?	Assign each number to one of k buckets, backtrack when a bucket exceeds target:<br><pre><code>def canPartitionKSubsets(nums, k):<br>    total = sum(nums)<br>    if total % k != 0: return False<br>    target = total // k<br>    nums.sort(reverse=True)  # try large numbers first<br>    buckets = [0] * k<br>    def backtrack(index):<br>        if index == len(nums): return all(b == target for b in buckets)<br>        for i in range(k):<br>            if buckets[i] + nums[index] > target: continue<br>            # Pruning: skip duplicate bucket states<br>            if i > 0 and buckets[i] == buckets[i-1]: continue<br>            buckets[i] += nums[index]<br>            if backtrack(index + 1): return True<br>            buckets[i] -= nums[index]<br>        return False<br>    return backtrack(0)</code></pre><br><b>Time: O(k^n)</b> worst case, but pruning makes it practical. Sorting descending tries large numbers first, failing faster. The duplicate bucket skip avoids trying the same number in two empty buckets.	backtracking::constraint
What is the difference between mutable and immutable state in backtracking?	<b>Mutable (list/array):</b> Must explicitly undo changes. More memory-efficient.<br><pre><code># Mutable: need choose + unchoose<br>current.append(choice)<br>backtrack(...)<br>current.pop()          # explicit undo required</code></pre><br><b>Immutable (string, tuple, int):</b> No undo needed — each call gets its own copy.<br><pre><code># Immutable: no undo needed<br>backtrack(current + choice)   # creates new string<br>backtrack(remaining - value)  # new integer, original unchanged</code></pre><br><b>Trade-off:</b> Mutable is faster (no copying) but error-prone (forget to pop → bug). Immutable is cleaner but creates more objects. In interviews, choose whichever makes the code clearer — for strings, concatenation is usually cleaner; for lists of elements, append/pop is standard.	backtracking::template
How do you approach recursion problems systematically?	<b>Step-by-step framework:</b><br><br><b>1. Identify the subproblem:</b> What smaller version of this problem would help solve the current one?<br><br><b>2. Define the base case:</b> What's the smallest/simplest input? What should it return?<br><br><b>3. Decide on parameters:</b> What state changes between calls? What stays constant?<br><br><b>4. Define the recursive relationship:</b> How do subproblem results combine to solve the current problem?<br><br><b>5. Decide on return value:</b> Am I aggregating (return sum), searching (return bool), or collecting (void + side effect)?<br><br><b>Quick check questions:</b><br>• Does each call move toward the base case? (Progress)<br>• Have I handled all base cases? (Termination)<br>• Am I doing work before, between, or after recursive calls? (Pre/In/Post-order)<br>• Am I modifying shared state? (Need undo for backtracking)	recursion::fundamentals
What is divide and conquer, and how does it use recursion?	<b>Divide and conquer:</b> Split the problem into independent subproblems, solve each recursively, then combine results:<br><pre><code># Merge Sort: classic divide and conquer<br>def mergeSort(arr):<br>    if len(arr) <= 1: return arr<br>    mid = len(arr) // 2<br>    left = mergeSort(arr[:mid])    # divide<br>    right = mergeSort(arr[mid:])   # divide<br>    return merge(left, right)      # conquer (combine)</code></pre><br><b>Three steps:</b><br>1. <b>Divide:</b> Split into smaller subproblems<br>2. <b>Conquer:</b> Solve each recursively<br>3. <b>Combine:</b> Merge subproblem results<br><br><b>Differs from backtracking:</b> Divide and conquer splits into <b>independent</b> subproblems (no shared state, no undoing). Backtracking makes <b>sequential choices</b> in a shared search space with undo.	recursion::patterns
How do you solve "Power(x, n)" efficiently with recursion?	Use the mathematical identity: x^n = (x^(n/2))² to achieve O(log n):<br><pre><code>def myPow(x, n):<br>    if n == 0: return 1<br>    if n < 0: return myPow(1/x, -n)<br>    if n % 2 == 0:<br>        half = myPow(x, n // 2)<br>        return half * half  # square the half result<br>    else:<br>        return x * myPow(x, n - 1)</code></pre><br><b>Time: O(log n), Space: O(log n)</b>. Naive approach is O(n) multiplications. By halving n each time, we only need ~log n recursive calls. Store <code>half</code> to avoid computing it twice (otherwise it becomes O(n) again).	recursion::patterns
How do you flatten a nested list recursively?	Check each element — if it's a list, recurse; otherwise, add it:<br><pre><code>def flatten(nested):<br>    result = []<br>    for item in nested:<br>        if isinstance(item, list):<br>            result.extend(flatten(item))  # recurse on sublist<br>        else:<br>            result.append(item)  # base: not a list<br>    return result<br><br># [1, [2, [3, 4], 5], 6] → [1, 2, 3, 4, 5, 6]</code></pre><br><b>Time: O(n) total elements, Space: O(d)</b> where d = max nesting depth.<br><br>This pattern applies to any nested/recursive data structure: JSON parsing, directory traversal, expression evaluation. The recursion naturally mirrors the data's recursive structure.	recursion::patterns
How does backtracking relate to DFS on a decision tree?	<b>Every backtracking problem is a DFS of an implicit decision tree.</b> The tree nodes are states, edges are choices:<br><pre><code>Permutations of [1,2,3] decision tree:<br><br>              []               ← root (empty)<br>           /  |  \<br>         [1] [2] [3]           ← choose first element<br>        / \   |   / \<br>    [1,2][1,3] ... [3,1][3,2]  ← choose second<br>      |    |         |    |<br>  [1,2,3][1,3,2]  [3,1,2][3,2,1] ← choose third (leaves)</code></pre><br><b>DFS traversal of this tree = backtracking algorithm.</b><br>• Going deeper = making a choice<br>• Reaching a leaf = found a solution (or dead end)<br>• Backtracking = going back up to try the next sibling<br><br>Understanding this lets you analyze any backtracking problem by drawing its decision tree first, then coding the DFS.	backtracking::template
What are the complexity classes for common backtracking problems?	<b>Time complexities (output-dependent):</b><br><br>• Subsets: <b>O(n × 2ⁿ)</b> — 2ⁿ subsets, O(n) to copy<br>• Permutations: <b>O(n × n!)</b> — n! arrangements, O(n) to copy<br>• Combinations C(n,k): <b>O(k × C(n,k))</b><br>• Generate parentheses: <b>O(4ⁿ/√n)</b> — nth Catalan number<br>• N-Queens: <b>O(n!)</b> — n choices, then n-1, then n-2...<br>• Sudoku: <b>O(9^m)</b> — m empty cells, 9 choices each<br>• Word Search: <b>O(m×n × 4^L)</b> — start each cell, 4 directions × word length<br><br><b>Space: O(depth)</b> for the recursion stack, usually O(n) or O(L) where L = solution length. Plus O(output) for storing results.	backtracking::template
How do you solve "Letter Case Permutation" (toggle letter cases)?	At each character: if it's a letter, branch into lowercase and uppercase. If digit, just proceed:<br><pre><code>def letterCasePermutation(s):<br>    result = []<br>    def backtrack(index, current):<br>        if index == len(s):<br>            result.append(current)<br>            return<br>        char = s[index]<br>        if char.isalpha():<br>            backtrack(index+1, current + char.lower())<br>            backtrack(index+1, current + char.upper())<br>        else:<br>            backtrack(index+1, current + char)<br>    backtrack(0, "")<br>    return result</code></pre><br><b>Time: O(n × 2^L)</b> where L = number of letters. Digits create no branching. This is the subset pattern where "include/exclude" becomes "lowercase/uppercase." The decision tree has 2 branches at letters, 1 branch at digits.	backtracking::generation
How do you solve "Path Sum II" (find all root-to-leaf paths that sum to target)?	DFS with backtracking to collect paths:<br><pre><code>def pathSum(root, targetSum):<br>    result = []<br>    def dfs(node, remaining, path):<br>        if not node: return<br>        path.append(node.val)<br>        if not node.left and not node.right and remaining == node.val:<br>            result.append(path[:])  # found valid path<br>        dfs(node.left, remaining - node.val, path)<br>        dfs(node.right, remaining - node.val, path)<br>        path.pop()  # backtrack<br>    dfs(root, targetSum, [])<br>    return result</code></pre><br><b>Time: O(n²)</b> worst case (n nodes × n to copy path). <b>Space: O(n)</b>.<br><br>The <code>path.pop()</code> after both recursive calls is the backtracking step — undo the current node so sibling branches don't see it. Check the sum at <b>leaves only</b> (not null nodes).	backtracking::tree
How do you generate all possible IP addresses, phone words, and similar "cartesian product" problems?	These all follow the same pattern: at each position, try all valid options and advance to the next position:<br><br><b>Template:</b><br><pre><code>def generate(choices_per_position):<br>    result = []<br>    def backtrack(index, current):<br>        if index == len(choices_per_position):<br>            result.append(current)<br>            return<br>        for choice in choices_per_position[index]:<br>            if is_valid(choice, current):  # optional constraint<br>                backtrack(index + 1, current + choice)<br>    backtrack(0, "")<br>    return result</code></pre><br>This covers:<br>• <b>Phone letters:</b> choices_per_position = letters for each digit<br>• <b>IP addresses:</b> choices = 1-3 digit segments, constraint = 0-255<br>• <b>Binary strings:</b> choices = ["0", "1"] at each position<br>• <b>Parentheses:</b> choices = ["(", ")"] with balance constraints	backtracking::generation
What are the most common mistakes in recursion and backtracking?	<b>1. Missing base case:</b> Infinite recursion → stack overflow. Always define when to stop FIRST.<br><br><b>2. Not progressing toward base case:</b> If parameters don't change, you recurse forever.<br><pre><code>def bad(n): return bad(n)  # n never decreases!</code></pre><br><b>3. Forgetting to undo (backtracking):</b> The #1 backtracking bug. Without <code>path.pop()</code>, siblings see stale state from previous branches.<br><br><b>4. Not copying when recording:</b> <code>result.append(path)</code> instead of <code>result.append(path[:])</code> means all results share one list.<br><br><b>5. Wrong base case boundary:</b> Off-by-one in <code>index == len(arr)</code> vs <code>index >= len(arr)</code>.<br><br><b>6. Modifying shared state accidentally:</b> Using <code>arr.sort()</code> inside recursion, or mutating input without restoring.<br><br><b>Debug tip:</b> Print indented traces showing depth, parameters, and return values.	recursion::fundamentals
What is the relationship between backtracking, DFS, and BFS for problem solving?	<b>Backtracking = DFS on a decision tree.</b> It explores one complete path before trying alternatives:<br><pre><code>Go deep → hit dead end or solution → back up → try next branch</code></pre><br><b>BFS explores level by level</b> — useful when you need the shortest/shallowest solution but requires more memory (stores entire level).<br><br><b>When to use each:</b><br>• Need ALL solutions → <b>Backtracking (DFS)</b><br>• Need SHORTEST solution → <b>BFS</b><br>• Need ANY one solution → <b>Backtracking with early return</b><br>• Need OPTIMAL solution → <b>BFS (if unweighted) or DP</b><br><br><b>Memory:</b> Backtracking stores one path at a time: O(depth). BFS stores an entire level: O(branching^depth). This is why backtracking is preferred for search spaces with many solutions.	recursion::fundamentals
